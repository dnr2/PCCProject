A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."

The Harley J. Earl Trophy is named after General Motors car designer Harley Earl. Earl, the second commissioner of NASCAR, was the designer of the Chevrolet Corvette;[1] his Firebird I concept car provides the basis of the automobile that sits atop the trophy;[2] the car is often misidentified as Sir Malcolm Campbell's "Blue Bird" land speed record car.[3] Earl was a friend of NASCAR founder Bill France, Sr., who named the trophy after him as a sign of respect.[4]

The trophy is awarded to the winner of the annual Daytona 500, known as "The Great American Race",[5] which acts as the season-opening event for the NASCAR Sprint Cup Series (formerly known as the Nextel Cup Series, Winston Cup Series, and Grand National Series), and is also considered the most prestigious and important event on the NASCAR schedule.[2] The trophy is considered to be the most coveted award a NASCAR driver can be presented with.[2][6]

The Harley J. Earl Perpetual Trophy, the "official" version of the award, is housed at Daytona 500 Experience, a museum adjacent to the Daytona International Speedway. It stands about four feet tall, and five feet wide, and is in the same triangular "tri-oval" shape of Daytona International Speedway. It is removed from its display once a year to appear in victory lane with the winner of the Daytona 500.[7] However, in 2010, the trophy was removed from the Daytona International Speedway, and transported to the Indianapolis Motor Speedway, where it was put on display alongside the Borg-Warner Trophy, awarded to the winner of the Indianapolis 500, in the Indianapolis Motor Speedway Hall of Fame Museum during the Indianapolis 500 Week.[8]

The Trophy and the Award[edit]

2008 gold-plated trophy.
Winners of the Daytona 500 through 1997 received the Harley Earl Award, a wooden trophy approximately three feet tall, adorned with silver figurines.[9] Starting in 1998, to celebrate the 40th running, individual winners of the Daytona 500 have been presented with a miniature replica of the Harley J. Earl Trophy,[9] which was recreated by John Lajba, a sculptor from Omaha, Nebraska.[6] Previously commissioned to craft a sculpture of Bill France and his wife, Ann France, for display in front of NASCAR corporate headquarters in Daytona Beach, Florida,[6] Lajba's work on each replica trophy requires six weeks of 12-hour days to create the Firebird I automobile, with all the work done by hand,[6] before it gets plated in silver by A&J Plating, also located in Omaha.[6] The first replica trophy, won in 1998 by Dale Earnhardt was originally on a marble base, but has since been switched to an acrylic stand, making it lighter.[6] For the 2008 Daytona 500, the 50th anniversary of the first race, the replica of the trophy, presented to winner Ryan Newman, was plated in gold rather than silver.[5]

The replica trophies weigh 54 pounds (24 kg), and measure 18 inches (460 mm) tall, 22 inches (560 mm) wide and 12 inches (300 mm) deep.[7]

Additional Daytona 500 trophies[edit]
The Harley J. Earl Trophy is not the only trophy awarded at the conclusion of the annual Daytona 500. The crew chief of the winning team receives the Cannonball Baker Trophy, named after the first commissioner of NASCAR; the winning team owner is awarded the Governor's Cup.[10]

Winners of the Harley J. Earl Trophy[edit]
The most Harley Earl Awards and Harley J. Earl Trophy Replicas have been won by Richard Petty, often referred to as "The King" of NASCAR.[11] Petty's seven victories lead the four Daytona 500 wins of Cale Yarborough, and three each by Bobby Allison, Dale Jarrett and Jeff Gordon. Bill Elliott, Sterling Marlin, Michael Waltrip, Matt Kenseth, Jimmie Johnson and Dale Earnhardt, Jr. have won the Daytona 500 and Harley J. Earl Trophy twice; twenty-six other drivers have been awarded the trophy once.[12] As of 2012, Trevor Bayne was the youngest winner of the trophy when he won it at age 20 years, 1 day in 2011;[13] Allison was the oldest winner (50 years, 2 months, 11 days) in 1988.[14]
The Harley J. Earl Trophy is named after General Motors car designer Harley Earl. Earl, the second commissioner of NASCAR, was the designer of the Chevrolet Corvette;[1] his Firebird I concept car provides the basis of the automobile that sits atop the trophy;[2] the car is often misidentified as Sir Malcolm Campbell's "Blue Bird" land speed record car.[3] Earl was a friend of NASCAR founder Bill France, Sr., who named the trophy after him as a sign of respect.[4]

The trophy is awarded to the winner of the annual Daytona 500, known as "The Great American Race",[5] which acts as the season-opening event for the NASCAR Sprint Cup Series (formerly known as the Nextel Cup Series, Winston Cup Series, and Grand National Series), and is also considered the most prestigious and important event on the NASCAR schedule.[2] The trophy is considered to be the most coveted award a NASCAR driver can be presented with.[2][6]

The Harley J. Earl Perpetual Trophy, the "official" version of the award, is housed at Daytona 500 Experience, a museum adjacent to the Daytona International Speedway. It stands about four feet tall, and five feet wide, and is in the same triangular "tri-oval" shape of Daytona International Speedway. It is removed from its display once a year to appear in victory lane with the winner of the Daytona 500.[7] However, in 2010, the trophy was removed from the Daytona International Speedway, and transported to the Indianapolis Motor Speedway, where it was put on display alongside the Borg-Warner Trophy, awarded to the winner of the Indianapolis 500, in the Indianapolis Motor Speedway Hall of Fame Museum during the Indianapolis 500 Week.[8]

The Trophy and the Award[edit]

2008 gold-plated trophy.
Winners of the Daytona 500 through 1997 received the Harley Earl Award, a wooden trophy approximately three feet tall, adorned with silver figurines.[9] Starting in 1998, to celebrate the 40th running, individual winners of the Daytona 500 have been presented with a miniature replica of the Harley J. Earl Trophy,[9] which was recreated by John Lajba, a sculptor from Omaha, Nebraska.[6] Previously commissioned to craft a sculpture of Bill France and his wife, Ann France, for display in front of NASCAR corporate headquarters in Daytona Beach, Florida,[6] Lajba's work on each replica trophy requires six weeks of 12-hour days to create the Firebird I automobile, with all the work done by hand,[6] before it gets plated in silver by A&J Plating, also located in Omaha.[6] The first replica trophy, won in 1998 by Dale Earnhardt was originally on a marble base, but has since been switched to an acrylic stand, making it lighter.[6] For the 2008 Daytona 500, the 50th anniversary of the first race, the replica of the trophy, presented to winner Ryan Newman, was plated in gold rather than silver.[5]

The replica trophies weigh 54 pounds (24 kg), and measure 18 inches (460 mm) tall, 22 inches (560 mm) wide and 12 inches (300 mm) deep.[7]

Additional Daytona 500 trophies[edit]
The Harley J. Earl Trophy is not the only trophy awarded at the conclusion of the annual Daytona 500. The crew chief of the winning team receives the Cannonball Baker Trophy, named after the first commissioner of NASCAR; the winning team owner is awarded the Governor's Cup.[10]

Winners of the Harley J. Earl Trophy[edit]
The most Harley Earl Awards and Harley J. Earl Trophy Replicas have been won by Richard Petty, often referred to as "The King" of NASCAR.[11] Petty's seven victories lead the four Daytona 500 wins of Cale Yarborough, and three each by Bobby Allison, Dale Jarrett and Jeff Gordon. Bill Elliott, Sterling Marlin, Michael Waltrip, Matt Kenseth, Jimmie Johnson and Dale Earnhardt, Jr. have won the Daytona 500 and Harley J. Earl Trophy twice; twenty-six other drivers have been awarded the trophy once.[12] As of 2012, Trevor Bayne was the youngest winner of the trophy when he won it at age 20 years, 1 day in 2011;[13] Allison was the oldest winner (50 years, 2 months, 11 days) in 1988.[14]
In Flash Hiders there are three different play modes: a scenario mode, an "Advance mode", and a versus mode.[1] While the scenario mode limits the player to using protagonist Bang Vipot, the "Advance mode" allows the player to use his or her favorite character.[1] While the game requires the Super CD (known in North America as Turbo CD) to run, it is recommended that the "Arcade Card" is installed in the PC Engine for the game to run at its intended speed. If the game is played with a two-button controller, gently pressing the punch or kick button results in a weak attack while holding the button down executes a harder attack. If it is played with a six-button controller, four basic attacks from weak punch to hard kick are assigned to the first four buttons. Each fighter has three other gauges besides his or her health; the strength of the attacks, the speed of the player, and the toughness of the defense.

Characters[edit]
Bang Vipot: The protagonist of the game. A kickboxer from the Wallace tribe who uses the ability to turn into a tiger in one of his moves.

Tiria Rosette: A bojutsu practitioner from the Meijia tribe who uses the fire spirit, Ifreis.

Ottoh Halford: A member of the cyborg tribe, Boranzo. He also wields crowbar-tip claws on his hand.

Harman Do Elan: A member of the Wallace tribe who uses the ability to turn into a panther in one of her moves.

Rablehalt: A sword-wielding knight of the Wallace tribe who can turn into a werewolf in one of his moves.

Spenoza Thunderhead: A member of the Meijia tribe who uses the thunder spirit, Bolvick.

Calnarsa Lue Bonn: A bojutsu expert from the Boranzo tribe.

Horow: A ninja from the Boranzo tribe.

Seena Vanpied: A vampire from the Meijia tribe who uses the ice spirit, Windy.

Graneel: The game's sub-boss. He is a member of the Wallace tribe who wields a lance and can turn into a dragon.

Moonrize: The game's antagonist. A secretary of Spenoza and also a member of the Boranzo tribe.

Battle Tycoon: Flash Hiders SFX[edit]
Battle Tycoon: Flash Hiders SFX
Battle Tycoon: Flash Hiders SFX
Front cover.
Developer(s)	Right Stuff
Publisher(s)	Right Stuff
Platform(s)	Super Famicom
Release date(s)	
JP May 19, 1995
Genre(s)	Action with role-playing video game elements[2]
Mode(s)	Single-player
Multiplayer (up to 2 players)
Battle Tycoon: Flash Hiders SFX (バトルタイクーン?)[3] is a 1995 fighting video game developed and published by Right Stuff for the Super Famicom on May 19, 1995. It is an alleged sequel to the 1993 PC Engine CD-ROM ² title Flash Hiders.[4] Like its predecessor, Battle Tycoon: Flash Hiders SFX simulates the life of a fantasy martial arts prize fighter with an anime theme to it.[2]

Gameplay[edit]
With the money that the player wins per fight, he or she can go to the store from sunrise to sunset and upgrade his or her equipment. From sunset to sunrise, the player can either bet on arena fights to gain extra cash or participate in them in order to gain experience points. Also, the player has the ability to fight on the streets during any moment of the day. Computer opponents that are defeated in low levels often come back in higher level formats, although they occasionally respawn as a lower level warrior. Sometimes, a player can even fight a clone of either himself or herself. This clone will either be superior, inferior, or on equal terms to the player's character. There are six difficulty levels; Easy, Normal, Hard, Metal, Truth, and Death. The game can be played by either one or two players. There is no blood and fantasy violence (either with or without melee weapons) dominate most of the game.

By the end of most games, the player will have a wealthy, powerful fighter with the strongest gear and protection. Settings for fights can take place anywhere from military bases to arena and even the city streets. Each fighter has three other gauges besides his or her health; they determine the strength of the attacks, the speed of the player, and the toughness of the defense (guard).

Characters returned from Flash Hiders[edit]
Bang Vipot
Tiria Rosette
Ottoh Halford
Harman Do Elan
Spenoza Thunderhead
Calnarsa Lue Bonn
Seena Vanpied
Characters introduced in Battle Tycoon[edit]
Guston Slayed: A mixed martial artist of the Boranzo tribe.
Pachet Vain: A tomboyish swordswoman of the Wallace tribe who can turn into a polar bear in one of her moves.
Jail Lance: The game's antagonist. He is a sword-wielding member of the Wallace tribe who is also Bang's father. Though he has the spirit of a lion, he does not have a special move that will turn him into an animal unlike other Wallace tribe members.
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."

The Harley J. Earl Trophy is named after General Motors car designer Harley Earl. Earl, the second commissioner of NASCAR, was the designer of the Chevrolet Corvette;[1] his Firebird I concept car provides the basis of the automobile that sits atop the trophy;[2] the car is often misidentified as Sir Malcolm Campbell's "Blue Bird" land speed record car.[3] Earl was a friend of NASCAR founder Bill France, Sr., who named the trophy after him as a sign of respect.[4]

The trophy is awarded to the winner of the annual Daytona 500, known as "The Great American Race",[5] which acts as the season-opening event for the NASCAR Sprint Cup Series (formerly known as the Nextel Cup Series, Winston Cup Series, and Grand National Series), and is also considered the most prestigious and important event on the NASCAR schedule.[2] The trophy is considered to be the most coveted award a NASCAR driver can be presented with.[2][6]

The Harley J. Earl Perpetual Trophy, the "official" version of the award, is housed at Daytona 500 Experience, a museum adjacent to the Daytona International Speedway. It stands about four feet tall, and five feet wide, and is in the same triangular "tri-oval" shape of Daytona International Speedway. It is removed from its display once a year to appear in victory lane with the winner of the Daytona 500.[7] However, in 2010, the trophy was removed from the Daytona International Speedway, and transported to the Indianapolis Motor Speedway, where it was put on display alongside the Borg-Warner Trophy, awarded to the winner of the Indianapolis 500, in the Indianapolis Motor Speedway Hall of Fame Museum during the Indianapolis 500 Week.[8]

The Trophy and the Award[edit]

2008 gold-plated trophy.
Winners of the Daytona 500 through 1997 received the Harley Earl Award, a wooden trophy approximately three feet tall, adorned with silver figurines.[9] Starting in 1998, to celebrate the 40th running, individual winners of the Daytona 500 have been presented with a miniature replica of the Harley J. Earl Trophy,[9] which was recreated by John Lajba, a sculptor from Omaha, Nebraska.[6] Previously commissioned to craft a sculpture of Bill France and his wife, Ann France, for display in front of NASCAR corporate headquarters in Daytona Beach, Florida,[6] Lajba's work on each replica trophy requires six weeks of 12-hour days to create the Firebird I automobile, with all the work done by hand,[6] before it gets plated in silver by A&J Plating, also located in Omaha.[6] The first replica trophy, won in 1998 by Dale Earnhardt was originally on a marble base, but has since been switched to an acrylic stand, making it lighter.[6] For the 2008 Daytona 500, the 50th anniversary of the first race, the replica of the trophy, presented to winner Ryan Newman, was plated in gold rather than silver.[5]

The replica trophies weigh 54 pounds (24 kg), and measure 18 inches (460 mm) tall, 22 inches (560 mm) wide and 12 inches (300 mm) deep.[7]

Additional Daytona 500 trophies[edit]
The Harley J. Earl Trophy is not the only trophy awarded at the conclusion of the annual Daytona 500. The crew chief of the winning team receives the Cannonball Baker Trophy, named after the first commissioner of NASCAR; the winning team owner is awarded the Governor's Cup.[10]

Winners of the Harley J. Earl Trophy[edit]
The most Harley Earl Awards and Harley J. Earl Trophy Replicas have been won by Richard Petty, often referred to as "The King" of NASCAR.[11] Petty's seven victories lead the four Daytona 500 wins of Cale Yarborough, and three each by Bobby Allison, Dale Jarrett and Jeff Gordon. Bill Elliott, Sterling Marlin, Michael Waltrip, Matt Kenseth, Jimmie Johnson and Dale Earnhardt, Jr. have won the Daytona 500 and Harley J. Earl Trophy twice; twenty-six other drivers have been awarded the trophy once.[12] As of 2012, Trevor Bayne was the youngest winner of the trophy when he won it at age 20 years, 1 day in 2011;[13] Allison was the oldest winner (50 years, 2 months, 11 days) in 1988.[14]
The Harley J. Earl Trophy is named after General Motors car designer Harley Earl. Earl, the second commissioner of NASCAR, was the designer of the Chevrolet Corvette;[1] his Firebird I concept car provides the basis of the automobile that sits atop the trophy;[2] the car is often misidentified as Sir Malcolm Campbell's "Blue Bird" land speed record car.[3] Earl was a friend of NASCAR founder Bill France, Sr., who named the trophy after him as a sign of respect.[4]

The trophy is awarded to the winner of the annual Daytona 500, known as "The Great American Race",[5] which acts as the season-opening event for the NASCAR Sprint Cup Series (formerly known as the Nextel Cup Series, Winston Cup Series, and Grand National Series), and is also considered the most prestigious and important event on the NASCAR schedule.[2] The trophy is considered to be the most coveted award a NASCAR driver can be presented with.[2][6]

The Harley J. Earl Perpetual Trophy, the "official" version of the award, is housed at Daytona 500 Experience, a museum adjacent to the Daytona International Speedway. It stands about four feet tall, and five feet wide, and is in the same triangular "tri-oval" shape of Daytona International Speedway. It is removed from its display once a year to appear in victory lane with the winner of the Daytona 500.[7] However, in 2010, the trophy was removed from the Daytona International Speedway, and transported to the Indianapolis Motor Speedway, where it was put on display alongside the Borg-Warner Trophy, awarded to the winner of the Indianapolis 500, in the Indianapolis Motor Speedway Hall of Fame Museum during the Indianapolis 500 Week.[8]

The Trophy and the Award[edit]

2008 gold-plated trophy.
Winners of the Daytona 500 through 1997 received the Harley Earl Award, a wooden trophy approximately three feet tall, adorned with silver figurines.[9] Starting in 1998, to celebrate the 40th running, individual winners of the Daytona 500 have been presented with a miniature replica of the Harley J. Earl Trophy,[9] which was recreated by John Lajba, a sculptor from Omaha, Nebraska.[6] Previously commissioned to craft a sculpture of Bill France and his wife, Ann France, for display in front of NASCAR corporate headquarters in Daytona Beach, Florida,[6] Lajba's work on each replica trophy requires six weeks of 12-hour days to create the Firebird I automobile, with all the work done by hand,[6] before it gets plated in silver by A&J Plating, also located in Omaha.[6] The first replica trophy, won in 1998 by Dale Earnhardt was originally on a marble base, but has since been switched to an acrylic stand, making it lighter.[6] For the 2008 Daytona 500, the 50th anniversary of the first race, the replica of the trophy, presented to winner Ryan Newman, was plated in gold rather than silver.[5]

The replica trophies weigh 54 pounds (24 kg), and measure 18 inches (460 mm) tall, 22 inches (560 mm) wide and 12 inches (300 mm) deep.[7]

Additional Daytona 500 trophies[edit]
The Harley J. Earl Trophy is not the only trophy awarded at the conclusion of the annual Daytona 500. The crew chief of the winning team receives the Cannonball Baker Trophy, named after the first commissioner of NASCAR; the winning team owner is awarded the Governor's Cup.[10]

Winners of the Harley J. Earl Trophy[edit]
The most Harley Earl Awards and Harley J. Earl Trophy Replicas have been won by Richard Petty, often referred to as "The King" of NASCAR.[11] Petty's seven victories lead the four Daytona 500 wins of Cale Yarborough, and three each by Bobby Allison, Dale Jarrett and Jeff Gordon. Bill Elliott, Sterling Marlin, Michael Waltrip, Matt Kenseth, Jimmie Johnson and Dale Earnhardt, Jr. have won the Daytona 500 and Harley J. Earl Trophy twice; twenty-six other drivers have been awarded the trophy once.[12] As of 2012, Trevor Bayne was the youngest winner of the trophy when he won it at age 20 years, 1 day in 2011;[13] Allison was the oldest winner (50 years, 2 months, 11 days) in 1988.[14]
In Flash Hiders there are three different play modes: a scenario mode, an "Advance mode", and a versus mode.[1] While the scenario mode limits the player to using protagonist Bang Vipot, the "Advance mode" allows the player to use his or her favorite character.[1] While the game requires the Super CD (known in North America as Turbo CD) to run, it is recommended that the "Arcade Card" is installed in the PC Engine for the game to run at its intended speed. If the game is played with a two-button controller, gently pressing the punch or kick button results in a weak attack while holding the button down executes a harder attack. If it is played with a six-button controller, four basic attacks from weak punch to hard kick are assigned to the first four buttons. Each fighter has three other gauges besides his or her health; the strength of the attacks, the speed of the player, and the toughness of the defense.

Characters[edit]
Bang Vipot: The protagonist of the game. A kickboxer from the Wallace tribe who uses the ability to turn into a tiger in one of his moves.

Tiria Rosette: A bojutsu practitioner from the Meijia tribe who uses the fire spirit, Ifreis.

Ottoh Halford: A member of the cyborg tribe, Boranzo. He also wields crowbar-tip claws on his hand.

Harman Do Elan: A member of the Wallace tribe who uses the ability to turn into a panther in one of her moves.

Rablehalt: A sword-wielding knight of the Wallace tribe who can turn into a werewolf in one of his moves.

Spenoza Thunderhead: A member of the Meijia tribe who uses the thunder spirit, Bolvick.

Calnarsa Lue Bonn: A bojutsu expert from the Boranzo tribe.

Horow: A ninja from the Boranzo tribe.

Seena Vanpied: A vampire from the Meijia tribe who uses the ice spirit, Windy.

Graneel: The game's sub-boss. He is a member of the Wallace tribe who wields a lance and can turn into a dragon.

Moonrize: The game's antagonist. A secretary of Spenoza and also a member of the Boranzo tribe.

Battle Tycoon: Flash Hiders SFX[edit]
Battle Tycoon: Flash Hiders SFX
Battle Tycoon: Flash Hiders SFX
Front cover.
Developer(s)	Right Stuff
Publisher(s)	Right Stuff
Platform(s)	Super Famicom
Release date(s)	
JP May 19, 1995
Genre(s)	Action with role-playing video game elements[2]
Mode(s)	Single-player
Multiplayer (up to 2 players)
Battle Tycoon: Flash Hiders SFX (バトルタイクーン?)[3] is a 1995 fighting video game developed and published by Right Stuff for the Super Famicom on May 19, 1995. It is an alleged sequel to the 1993 PC Engine CD-ROM ² title Flash Hiders.[4] Like its predecessor, Battle Tycoon: Flash Hiders SFX simulates the life of a fantasy martial arts prize fighter with an anime theme to it.[2]

Gameplay[edit]
With the money that the player wins per fight, he or she can go to the store from sunrise to sunset and upgrade his or her equipment. From sunset to sunrise, the player can either bet on arena fights to gain extra cash or participate in them in order to gain experience points. Also, the player has the ability to fight on the streets during any moment of the day. Computer opponents that are defeated in low levels often come back in higher level formats, although they occasionally respawn as a lower level warrior. Sometimes, a player can even fight a clone of either himself or herself. This clone will either be superior, inferior, or on equal terms to the player's character. There are six difficulty levels; Easy, Normal, Hard, Metal, Truth, and Death. The game can be played by either one or two players. There is no blood and fantasy violence (either with or without melee weapons) dominate most of the game.

By the end of most games, the player will have a wealthy, powerful fighter with the strongest gear and protection. Settings for fights can take place anywhere from military bases to arena and even the city streets. Each fighter has three other gauges besides his or her health; they determine the strength of the attacks, the speed of the player, and the toughness of the defense (guard).

Characters returned from Flash Hiders[edit]
Bang Vipot
Tiria Rosette
Ottoh Halford
Harman Do Elan
Spenoza Thunderhead
Calnarsa Lue Bonn
Seena Vanpied
Characters introduced in Battle Tycoon[edit]
Guston Slayed: A mixed martial artist of the Boranzo tribe.
Pachet Vain: A tomboyish swordswoman of the Wallace tribe who can turn into a polar bear in one of her moves.
Jail Lance: The game's antagonist. He is a sword-wielding member of the Wallace tribe who is also Bang's father. Though he has the spirit of a lion, he does not have a special move that will turn him into an animal unlike other Wallace tribe members.
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."

The Harley J. Earl Trophy is named after General Motors car designer Harley Earl. Earl, the second commissioner of NASCAR, was the designer of the Chevrolet Corvette;[1] his Firebird I concept car provides the basis of the automobile that sits atop the trophy;[2] the car is often misidentified as Sir Malcolm Campbell's "Blue Bird" land speed record car.[3] Earl was a friend of NASCAR founder Bill France, Sr., who named the trophy after him as a sign of respect.[4]

The trophy is awarded to the winner of the annual Daytona 500, known as "The Great American Race",[5] which acts as the season-opening event for the NASCAR Sprint Cup Series (formerly known as the Nextel Cup Series, Winston Cup Series, and Grand National Series), and is also considered the most prestigious and important event on the NASCAR schedule.[2] The trophy is considered to be the most coveted award a NASCAR driver can be presented with.[2][6]

The Harley J. Earl Perpetual Trophy, the "official" version of the award, is housed at Daytona 500 Experience, a museum adjacent to the Daytona International Speedway. It stands about four feet tall, and five feet wide, and is in the same triangular "tri-oval" shape of Daytona International Speedway. It is removed from its display once a year to appear in victory lane with the winner of the Daytona 500.[7] However, in 2010, the trophy was removed from the Daytona International Speedway, and transported to the Indianapolis Motor Speedway, where it was put on display alongside the Borg-Warner Trophy, awarded to the winner of the Indianapolis 500, in the Indianapolis Motor Speedway Hall of Fame Museum during the Indianapolis 500 Week.[8]

The Trophy and the Award[edit]

2008 gold-plated trophy.
Winners of the Daytona 500 through 1997 received the Harley Earl Award, a wooden trophy approximately three feet tall, adorned with silver figurines.[9] Starting in 1998, to celebrate the 40th running, individual winners of the Daytona 500 have been presented with a miniature replica of the Harley J. Earl Trophy,[9] which was recreated by John Lajba, a sculptor from Omaha, Nebraska.[6] Previously commissioned to craft a sculpture of Bill France and his wife, Ann France, for display in front of NASCAR corporate headquarters in Daytona Beach, Florida,[6] Lajba's work on each replica trophy requires six weeks of 12-hour days to create the Firebird I automobile, with all the work done by hand,[6] before it gets plated in silver by A&J Plating, also located in Omaha.[6] The first replica trophy, won in 1998 by Dale Earnhardt was originally on a marble base, but has since been switched to an acrylic stand, making it lighter.[6] For the 2008 Daytona 500, the 50th anniversary of the first race, the replica of the trophy, presented to winner Ryan Newman, was plated in gold rather than silver.[5]

The replica trophies weigh 54 pounds (24 kg), and measure 18 inches (460 mm) tall, 22 inches (560 mm) wide and 12 inches (300 mm) deep.[7]

Additional Daytona 500 trophies[edit]
The Harley J. Earl Trophy is not the only trophy awarded at the conclusion of the annual Daytona 500. The crew chief of the winning team receives the Cannonball Baker Trophy, named after the first commissioner of NASCAR; the winning team owner is awarded the Governor's Cup.[10]

Winners of the Harley J. Earl Trophy[edit]
The most Harley Earl Awards and Harley J. Earl Trophy Replicas have been won by Richard Petty, often referred to as "The King" of NASCAR.[11] Petty's seven victories lead the four Daytona 500 wins of Cale Yarborough, and three each by Bobby Allison, Dale Jarrett and Jeff Gordon. Bill Elliott, Sterling Marlin, Michael Waltrip, Matt Kenseth, Jimmie Johnson and Dale Earnhardt, Jr. have won the Daytona 500 and Harley J. Earl Trophy twice; twenty-six other drivers have been awarded the trophy once.[12] As of 2012, Trevor Bayne was the youngest winner of the trophy when he won it at age 20 years, 1 day in 2011;[13] Allison was the oldest winner (50 years, 2 months, 11 days) in 1988.[14]
The Harley J. Earl Trophy is named after General Motors car designer Harley Earl. Earl, the second commissioner of NASCAR, was the designer of the Chevrolet Corvette;[1] his Firebird I concept car provides the basis of the automobile that sits atop the trophy;[2] the car is often misidentified as Sir Malcolm Campbell's "Blue Bird" land speed record car.[3] Earl was a friend of NASCAR founder Bill France, Sr., who named the trophy after him as a sign of respect.[4]

The trophy is awarded to the winner of the annual Daytona 500, known as "The Great American Race",[5] which acts as the season-opening event for the NASCAR Sprint Cup Series (formerly known as the Nextel Cup Series, Winston Cup Series, and Grand National Series), and is also considered the most prestigious and important event on the NASCAR schedule.[2] The trophy is considered to be the most coveted award a NASCAR driver can be presented with.[2][6]

The Harley J. Earl Perpetual Trophy, the "official" version of the award, is housed at Daytona 500 Experience, a museum adjacent to the Daytona International Speedway. It stands about four feet tall, and five feet wide, and is in the same triangular "tri-oval" shape of Daytona International Speedway. It is removed from its display once a year to appear in victory lane with the winner of the Daytona 500.[7] However, in 2010, the trophy was removed from the Daytona International Speedway, and transported to the Indianapolis Motor Speedway, where it was put on display alongside the Borg-Warner Trophy, awarded to the winner of the Indianapolis 500, in the Indianapolis Motor Speedway Hall of Fame Museum during the Indianapolis 500 Week.[8]

The Trophy and the Award[edit]

2008 gold-plated trophy.
Winners of the Daytona 500 through 1997 received the Harley Earl Award, a wooden trophy approximately three feet tall, adorned with silver figurines.[9] Starting in 1998, to celebrate the 40th running, individual winners of the Daytona 500 have been presented with a miniature replica of the Harley J. Earl Trophy,[9] which was recreated by John Lajba, a sculptor from Omaha, Nebraska.[6] Previously commissioned to craft a sculpture of Bill France and his wife, Ann France, for display in front of NASCAR corporate headquarters in Daytona Beach, Florida,[6] Lajba's work on each replica trophy requires six weeks of 12-hour days to create the Firebird I automobile, with all the work done by hand,[6] before it gets plated in silver by A&J Plating, also located in Omaha.[6] The first replica trophy, won in 1998 by Dale Earnhardt was originally on a marble base, but has since been switched to an acrylic stand, making it lighter.[6] For the 2008 Daytona 500, the 50th anniversary of the first race, the replica of the trophy, presented to winner Ryan Newman, was plated in gold rather than silver.[5]

The replica trophies weigh 54 pounds (24 kg), and measure 18 inches (460 mm) tall, 22 inches (560 mm) wide and 12 inches (300 mm) deep.[7]

Additional Daytona 500 trophies[edit]
The Harley J. Earl Trophy is not the only trophy awarded at the conclusion of the annual Daytona 500. The crew chief of the winning team receives the Cannonball Baker Trophy, named after the first commissioner of NASCAR; the winning team owner is awarded the Governor's Cup.[10]

Winners of the Harley J. Earl Trophy[edit]
The most Harley Earl Awards and Harley J. Earl Trophy Replicas have been won by Richard Petty, often referred to as "The King" of NASCAR.[11] Petty's seven victories lead the four Daytona 500 wins of Cale Yarborough, and three each by Bobby Allison, Dale Jarrett and Jeff Gordon. Bill Elliott, Sterling Marlin, Michael Waltrip, Matt Kenseth, Jimmie Johnson and Dale Earnhardt, Jr. have won the Daytona 500 and Harley J. Earl Trophy twice; twenty-six other drivers have been awarded the trophy once.[12] As of 2012, Trevor Bayne was the youngest winner of the trophy when he won it at age 20 years, 1 day in 2011;[13] Allison was the oldest winner (50 years, 2 months, 11 days) in 1988.[14]
In Flash Hiders there are three different play modes: a scenario mode, an "Advance mode", and a versus mode.[1] While the scenario mode limits the player to using protagonist Bang Vipot, the "Advance mode" allows the player to use his or her favorite character.[1] While the game requires the Super CD (known in North America as Turbo CD) to run, it is recommended that the "Arcade Card" is installed in the PC Engine for the game to run at its intended speed. If the game is played with a two-button controller, gently pressing the punch or kick button results in a weak attack while holding the button down executes a harder attack. If it is played with a six-button controller, four basic attacks from weak punch to hard kick are assigned to the first four buttons. Each fighter has three other gauges besides his or her health; the strength of the attacks, the speed of the player, and the toughness of the defense.

Characters[edit]
Bang Vipot: The protagonist of the game. A kickboxer from the Wallace tribe who uses the ability to turn into a tiger in one of his moves.

Tiria Rosette: A bojutsu practitioner from the Meijia tribe who uses the fire spirit, Ifreis.

Ottoh Halford: A member of the cyborg tribe, Boranzo. He also wields crowbar-tip claws on his hand.

Harman Do Elan: A member of the Wallace tribe who uses the ability to turn into a panther in one of her moves.

Rablehalt: A sword-wielding knight of the Wallace tribe who can turn into a werewolf in one of his moves.

Spenoza Thunderhead: A member of the Meijia tribe who uses the thunder spirit, Bolvick.

Calnarsa Lue Bonn: A bojutsu expert from the Boranzo tribe.

Horow: A ninja from the Boranzo tribe.

Seena Vanpied: A vampire from the Meijia tribe who uses the ice spirit, Windy.

Graneel: The game's sub-boss. He is a member of the Wallace tribe who wields a lance and can turn into a dragon.

Moonrize: The game's antagonist. A secretary of Spenoza and also a member of the Boranzo tribe.

Battle Tycoon: Flash Hiders SFX[edit]
Battle Tycoon: Flash Hiders SFX
Battle Tycoon: Flash Hiders SFX
Front cover.
Developer(s)	Right Stuff
Publisher(s)	Right Stuff
Platform(s)	Super Famicom
Release date(s)	
JP May 19, 1995
Genre(s)	Action with role-playing video game elements[2]
Mode(s)	Single-player
Multiplayer (up to 2 players)
Battle Tycoon: Flash Hiders SFX (バトルタイクーン?)[3] is a 1995 fighting video game developed and published by Right Stuff for the Super Famicom on May 19, 1995. It is an alleged sequel to the 1993 PC Engine CD-ROM ² title Flash Hiders.[4] Like its predecessor, Battle Tycoon: Flash Hiders SFX simulates the life of a fantasy martial arts prize fighter with an anime theme to it.[2]

Gameplay[edit]
With the money that the player wins per fight, he or she can go to the store from sunrise to sunset and upgrade his or her equipment. From sunset to sunrise, the player can either bet on arena fights to gain extra cash or participate in them in order to gain experience points. Also, the player has the ability to fight on the streets during any moment of the day. Computer opponents that are defeated in low levels often come back in higher level formats, although they occasionally respawn as a lower level warrior. Sometimes, a player can even fight a clone of either himself or herself. This clone will either be superior, inferior, or on equal terms to the player's character. There are six difficulty levels; Easy, Normal, Hard, Metal, Truth, and Death. The game can be played by either one or two players. There is no blood and fantasy violence (either with or without melee weapons) dominate most of the game.

By the end of most games, the player will have a wealthy, powerful fighter with the strongest gear and protection. Settings for fights can take place anywhere from military bases to arena and even the city streets. Each fighter has three other gauges besides his or her health; they determine the strength of the attacks, the speed of the player, and the toughness of the defense (guard).

Characters returned from Flash Hiders[edit]
Bang Vipot
Tiria Rosette
Ottoh Halford
Harman Do Elan
Spenoza Thunderhead
Calnarsa Lue Bonn
Seena Vanpied
Characters introduced in Battle Tycoon[edit]
Guston Slayed: A mixed martial artist of the Boranzo tribe.
Pachet Vain: A tomboyish swordswoman of the Wallace tribe who can turn into a polar bear in one of her moves.
Jail Lance: The game's antagonist. He is a sword-wielding member of the Wallace tribe who is also Bang's father. Though he has the spirit of a lion, he does not have a special move that will turn him into an animal unlike other Wallace tribe members.
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."

The Harley J. Earl Trophy is named after General Motors car designer Harley Earl. Earl, the second commissioner of NASCAR, was the designer of the Chevrolet Corvette;[1] his Firebird I concept car provides the basis of the automobile that sits atop the trophy;[2] the car is often misidentified as Sir Malcolm Campbell's "Blue Bird" land speed record car.[3] Earl was a friend of NASCAR founder Bill France, Sr., who named the trophy after him as a sign of respect.[4]

The trophy is awarded to the winner of the annual Daytona 500, known as "The Great American Race",[5] which acts as the season-opening event for the NASCAR Sprint Cup Series (formerly known as the Nextel Cup Series, Winston Cup Series, and Grand National Series), and is also considered the most prestigious and important event on the NASCAR schedule.[2] The trophy is considered to be the most coveted award a NASCAR driver can be presented with.[2][6]

The Harley J. Earl Perpetual Trophy, the "official" version of the award, is housed at Daytona 500 Experience, a museum adjacent to the Daytona International Speedway. It stands about four feet tall, and five feet wide, and is in the same triangular "tri-oval" shape of Daytona International Speedway. It is removed from its display once a year to appear in victory lane with the winner of the Daytona 500.[7] However, in 2010, the trophy was removed from the Daytona International Speedway, and transported to the Indianapolis Motor Speedway, where it was put on display alongside the Borg-Warner Trophy, awarded to the winner of the Indianapolis 500, in the Indianapolis Motor Speedway Hall of Fame Museum during the Indianapolis 500 Week.[8]

The Trophy and the Award[edit]

2008 gold-plated trophy.
Winners of the Daytona 500 through 1997 received the Harley Earl Award, a wooden trophy approximately three feet tall, adorned with silver figurines.[9] Starting in 1998, to celebrate the 40th running, individual winners of the Daytona 500 have been presented with a miniature replica of the Harley J. Earl Trophy,[9] which was recreated by John Lajba, a sculptor from Omaha, Nebraska.[6] Previously commissioned to craft a sculpture of Bill France and his wife, Ann France, for display in front of NASCAR corporate headquarters in Daytona Beach, Florida,[6] Lajba's work on each replica trophy requires six weeks of 12-hour days to create the Firebird I automobile, with all the work done by hand,[6] before it gets plated in silver by A&J Plating, also located in Omaha.[6] The first replica trophy, won in 1998 by Dale Earnhardt was originally on a marble base, but has since been switched to an acrylic stand, making it lighter.[6] For the 2008 Daytona 500, the 50th anniversary of the first race, the replica of the trophy, presented to winner Ryan Newman, was plated in gold rather than silver.[5]

The replica trophies weigh 54 pounds (24 kg), and measure 18 inches (460 mm) tall, 22 inches (560 mm) wide and 12 inches (300 mm) deep.[7]

Additional Daytona 500 trophies[edit]
The Harley J. Earl Trophy is not the only trophy awarded at the conclusion of the annual Daytona 500. The crew chief of the winning team receives the Cannonball Baker Trophy, named after the first commissioner of NASCAR; the winning team owner is awarded the Governor's Cup.[10]

Winners of the Harley J. Earl Trophy[edit]
The most Harley Earl Awards and Harley J. Earl Trophy Replicas have been won by Richard Petty, often referred to as "The King" of NASCAR.[11] Petty's seven victories lead the four Daytona 500 wins of Cale Yarborough, and three each by Bobby Allison, Dale Jarrett and Jeff Gordon. Bill Elliott, Sterling Marlin, Michael Waltrip, Matt Kenseth, Jimmie Johnson and Dale Earnhardt, Jr. have won the Daytona 500 and Harley J. Earl Trophy twice; twenty-six other drivers have been awarded the trophy once.[12] As of 2012, Trevor Bayne was the youngest winner of the trophy when he won it at age 20 years, 1 day in 2011;[13] Allison was the oldest winner (50 years, 2 months, 11 days) in 1988.[14]
The Harley J. Earl Trophy is named after General Motors car designer Harley Earl. Earl, the second commissioner of NASCAR, was the designer of the Chevrolet Corvette;[1] his Firebird I concept car provides the basis of the automobile that sits atop the trophy;[2] the car is often misidentified as Sir Malcolm Campbell's "Blue Bird" land speed record car.[3] Earl was a friend of NASCAR founder Bill France, Sr., who named the trophy after him as a sign of respect.[4]

The trophy is awarded to the winner of the annual Daytona 500, known as "The Great American Race",[5] which acts as the season-opening event for the NASCAR Sprint Cup Series (formerly known as the Nextel Cup Series, Winston Cup Series, and Grand National Series), and is also considered the most prestigious and important event on the NASCAR schedule.[2] The trophy is considered to be the most coveted award a NASCAR driver can be presented with.[2][6]

The Harley J. Earl Perpetual Trophy, the "official" version of the award, is housed at Daytona 500 Experience, a museum adjacent to the Daytona International Speedway. It stands about four feet tall, and five feet wide, and is in the same triangular "tri-oval" shape of Daytona International Speedway. It is removed from its display once a year to appear in victory lane with the winner of the Daytona 500.[7] However, in 2010, the trophy was removed from the Daytona International Speedway, and transported to the Indianapolis Motor Speedway, where it was put on display alongside the Borg-Warner Trophy, awarded to the winner of the Indianapolis 500, in the Indianapolis Motor Speedway Hall of Fame Museum during the Indianapolis 500 Week.[8]

The Trophy and the Award[edit]

2008 gold-plated trophy.
Winners of the Daytona 500 through 1997 received the Harley Earl Award, a wooden trophy approximately three feet tall, adorned with silver figurines.[9] Starting in 1998, to celebrate the 40th running, individual winners of the Daytona 500 have been presented with a miniature replica of the Harley J. Earl Trophy,[9] which was recreated by John Lajba, a sculptor from Omaha, Nebraska.[6] Previously commissioned to craft a sculpture of Bill France and his wife, Ann France, for display in front of NASCAR corporate headquarters in Daytona Beach, Florida,[6] Lajba's work on each replica trophy requires six weeks of 12-hour days to create the Firebird I automobile, with all the work done by hand,[6] before it gets plated in silver by A&J Plating, also located in Omaha.[6] The first replica trophy, won in 1998 by Dale Earnhardt was originally on a marble base, but has since been switched to an acrylic stand, making it lighter.[6] For the 2008 Daytona 500, the 50th anniversary of the first race, the replica of the trophy, presented to winner Ryan Newman, was plated in gold rather than silver.[5]

The replica trophies weigh 54 pounds (24 kg), and measure 18 inches (460 mm) tall, 22 inches (560 mm) wide and 12 inches (300 mm) deep.[7]

Additional Daytona 500 trophies[edit]
The Harley J. Earl Trophy is not the only trophy awarded at the conclusion of the annual Daytona 500. The crew chief of the winning team receives the Cannonball Baker Trophy, named after the first commissioner of NASCAR; the winning team owner is awarded the Governor's Cup.[10]

Winners of the Harley J. Earl Trophy[edit]
The most Harley Earl Awards and Harley J. Earl Trophy Replicas have been won by Richard Petty, often referred to as "The King" of NASCAR.[11] Petty's seven victories lead the four Daytona 500 wins of Cale Yarborough, and three each by Bobby Allison, Dale Jarrett and Jeff Gordon. Bill Elliott, Sterling Marlin, Michael Waltrip, Matt Kenseth, Jimmie Johnson and Dale Earnhardt, Jr. have won the Daytona 500 and Harley J. Earl Trophy twice; twenty-six other drivers have been awarded the trophy once.[12] As of 2012, Trevor Bayne was the youngest winner of the trophy when he won it at age 20 years, 1 day in 2011;[13] Allison was the oldest winner (50 years, 2 months, 11 days) in 1988.[14]
In Flash Hiders there are three different play modes: a scenario mode, an "Advance mode", and a versus mode.[1] While the scenario mode limits the player to using protagonist Bang Vipot, the "Advance mode" allows the player to use his or her favorite character.[1] While the game requires the Super CD (known in North America as Turbo CD) to run, it is recommended that the "Arcade Card" is installed in the PC Engine for the game to run at its intended speed. If the game is played with a two-button controller, gently pressing the punch or kick button results in a weak attack while holding the button down executes a harder attack. If it is played with a six-button controller, four basic attacks from weak punch to hard kick are assigned to the first four buttons. Each fighter has three other gauges besides his or her health; the strength of the attacks, the speed of the player, and the toughness of the defense.

Characters[edit]
Bang Vipot: The protagonist of the game. A kickboxer from the Wallace tribe who uses the ability to turn into a tiger in one of his moves.

Tiria Rosette: A bojutsu practitioner from the Meijia tribe who uses the fire spirit, Ifreis.

Ottoh Halford: A member of the cyborg tribe, Boranzo. He also wields crowbar-tip claws on his hand.

Harman Do Elan: A member of the Wallace tribe who uses the ability to turn into a panther in one of her moves.

Rablehalt: A sword-wielding knight of the Wallace tribe who can turn into a werewolf in one of his moves.

Spenoza Thunderhead: A member of the Meijia tribe who uses the thunder spirit, Bolvick.

Calnarsa Lue Bonn: A bojutsu expert from the Boranzo tribe.

Horow: A ninja from the Boranzo tribe.

Seena Vanpied: A vampire from the Meijia tribe who uses the ice spirit, Windy.

Graneel: The game's sub-boss. He is a member of the Wallace tribe who wields a lance and can turn into a dragon.

Moonrize: The game's antagonist. A secretary of Spenoza and also a member of the Boranzo tribe.

Battle Tycoon: Flash Hiders SFX[edit]
Battle Tycoon: Flash Hiders SFX
Battle Tycoon: Flash Hiders SFX
Front cover.
Developer(s)	Right Stuff
Publisher(s)	Right Stuff
Platform(s)	Super Famicom
Release date(s)	
JP May 19, 1995
Genre(s)	Action with role-playing video game elements[2]
Mode(s)	Single-player
Multiplayer (up to 2 players)
Battle Tycoon: Flash Hiders SFX (バトルタイクーン?)[3] is a 1995 fighting video game developed and published by Right Stuff for the Super Famicom on May 19, 1995. It is an alleged sequel to the 1993 PC Engine CD-ROM ² title Flash Hiders.[4] Like its predecessor, Battle Tycoon: Flash Hiders SFX simulates the life of a fantasy martial arts prize fighter with an anime theme to it.[2]

Gameplay[edit]
With the money that the player wins per fight, he or she can go to the store from sunrise to sunset and upgrade his or her equipment. From sunset to sunrise, the player can either bet on arena fights to gain extra cash or participate in them in order to gain experience points. Also, the player has the ability to fight on the streets during any moment of the day. Computer opponents that are defeated in low levels often come back in higher level formats, although they occasionally respawn as a lower level warrior. Sometimes, a player can even fight a clone of either himself or herself. This clone will either be superior, inferior, or on equal terms to the player's character. There are six difficulty levels; Easy, Normal, Hard, Metal, Truth, and Death. The game can be played by either one or two players. There is no blood and fantasy violence (either with or without melee weapons) dominate most of the game.

By the end of most games, the player will have a wealthy, powerful fighter with the strongest gear and protection. Settings for fights can take place anywhere from military bases to arena and even the city streets. Each fighter has three other gauges besides his or her health; they determine the strength of the attacks, the speed of the player, and the toughness of the defense (guard).

Characters returned from Flash Hiders[edit]
Bang Vipot
Tiria Rosette
Ottoh Halford
Harman Do Elan
Spenoza Thunderhead
Calnarsa Lue Bonn
Seena Vanpied
Characters introduced in Battle Tycoon[edit]
Guston Slayed: A mixed martial artist of the Boranzo tribe.
Pachet Vain: A tomboyish swordswoman of the Wallace tribe who can turn into a polar bear in one of her moves.
Jail Lance: The game's antagonist. He is a sword-wielding member of the Wallace tribe who is also Bang's father. Though he has the spirit of a lion, he does not have a special move that will turn him into an animal unlike other Wallace tribe members.

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."

The Harley J. Earl Trophy is named after General Motors car designer Harley Earl. Earl, the second commissioner of NASCAR, was the designer of the Chevrolet Corvette;[1] his Firebird I concept car provides the basis of the automobile that sits atop the trophy;[2] the car is often misidentified as Sir Malcolm Campbell's "Blue Bird" land speed record car.[3] Earl was a friend of NASCAR founder Bill France, Sr., who named the trophy after him as a sign of respect.[4]

The trophy is awarded to the winner of the annual Daytona 500, known as "The Great American Race",[5] which acts as the season-opening event for the NASCAR Sprint Cup Series (formerly known as the Nextel Cup Series, Winston Cup Series, and Grand National Series), and is also considered the most prestigious and important event on the NASCAR schedule.[2] The trophy is considered to be the most coveted award a NASCAR driver can be presented with.[2][6]

The Harley J. Earl Perpetual Trophy, the "official" version of the award, is housed at Daytona 500 Experience, a museum adjacent to the Daytona International Speedway. It stands about four feet tall, and five feet wide, and is in the same triangular "tri-oval" shape of Daytona International Speedway. It is removed from its display once a year to appear in victory lane with the winner of the Daytona 500.[7] However, in 2010, the trophy was removed from the Daytona International Speedway, and transported to the Indianapolis Motor Speedway, where it was put on display alongside the Borg-Warner Trophy, awarded to the winner of the Indianapolis 500, in the Indianapolis Motor Speedway Hall of Fame Museum during the Indianapolis 500 Week.[8]

The Trophy and the Award[edit]

2008 gold-plated trophy.
Winners of the Daytona 500 through 1997 received the Harley Earl Award, a wooden trophy approximately three feet tall, adorned with silver figurines.[9] Starting in 1998, to celebrate the 40th running, individual winners of the Daytona 500 have been presented with a miniature replica of the Harley J. Earl Trophy,[9] which was recreated by John Lajba, a sculptor from Omaha, Nebraska.[6] Previously commissioned to craft a sculpture of Bill France and his wife, Ann France, for display in front of NASCAR corporate headquarters in Daytona Beach, Florida,[6] Lajba's work on each replica trophy requires six weeks of 12-hour days to create the Firebird I automobile, with all the work done by hand,[6] before it gets plated in silver by A&J Plating, also located in Omaha.[6] The first replica trophy, won in 1998 by Dale Earnhardt was originally on a marble base, but has since been switched to an acrylic stand, making it lighter.[6] For the 2008 Daytona 500, the 50th anniversary of the first race, the replica of the trophy, presented to winner Ryan Newman, was plated in gold rather than silver.[5]

The replica trophies weigh 54 pounds (24 kg), and measure 18 inches (460 mm) tall, 22 inches (560 mm) wide and 12 inches (300 mm) deep.[7]

Additional Daytona 500 trophies[edit]
The Harley J. Earl Trophy is not the only trophy awarded at the conclusion of the annual Daytona 500. The crew chief of the winning team receives the Cannonball Baker Trophy, named after the first commissioner of NASCAR; the winning team owner is awarded the Governor's Cup.[10]

Winners of the Harley J. Earl Trophy[edit]
The most Harley Earl Awards and Harley J. Earl Trophy Replicas have been won by Richard Petty, often referred to as "The King" of NASCAR.[11] Petty's seven victories lead the four Daytona 500 wins of Cale Yarborough, and three each by Bobby Allison, Dale Jarrett and Jeff Gordon. Bill Elliott, Sterling Marlin, Michael Waltrip, Matt Kenseth, Jimmie Johnson and Dale Earnhardt, Jr. have won the Daytona 500 and Harley J. Earl Trophy twice; twenty-six other drivers have been awarded the trophy once.[12] As of 2012, Trevor Bayne was the youngest winner of the trophy when he won it at age 20 years, 1 day in 2011;[13] Allison was the oldest winner (50 years, 2 months, 11 days) in 1988.[14]
The Harley J. Earl Trophy is named after General Motors car designer Harley Earl. Earl, the second commissioner of NASCAR, was the designer of the Chevrolet Corvette;[1] his Firebird I concept car provides the basis of the automobile that sits atop the trophy;[2] the car is often misidentified as Sir Malcolm Campbell's "Blue Bird" land speed record car.[3] Earl was a friend of NASCAR founder Bill France, Sr., who named the trophy after him as a sign of respect.[4]

The trophy is awarded to the winner of the annual Daytona 500, known as "The Great American Race",[5] which acts as the season-opening event for the NASCAR Sprint Cup Series (formerly known as the Nextel Cup Series, Winston Cup Series, and Grand National Series), and is also considered the most prestigious and important event on the NASCAR schedule.[2] The trophy is considered to be the most coveted award a NASCAR driver can be presented with.[2][6]

The Harley J. Earl Perpetual Trophy, the "official" version of the award, is housed at Daytona 500 Experience, a museum adjacent to the Daytona International Speedway. It stands about four feet tall, and five feet wide, and is in the same triangular "tri-oval" shape of Daytona International Speedway. It is removed from its display once a year to appear in victory lane with the winner of the Daytona 500.[7] However, in 2010, the trophy was removed from the Daytona International Speedway, and transported to the Indianapolis Motor Speedway, where it was put on display alongside the Borg-Warner Trophy, awarded to the winner of the Indianapolis 500, in the Indianapolis Motor Speedway Hall of Fame Museum during the Indianapolis 500 Week.[8]

The Trophy and the Award[edit]

2008 gold-plated trophy.
Winners of the Daytona 500 through 1997 received the Harley Earl Award, a wooden trophy approximately three feet tall, adorned with silver figurines.[9] Starting in 1998, to celebrate the 40th running, individual winners of the Daytona 500 have been presented with a miniature replica of the Harley J. Earl Trophy,[9] which was recreated by John Lajba, a sculptor from Omaha, Nebraska.[6] Previously commissioned to craft a sculpture of Bill France and his wife, Ann France, for display in front of NASCAR corporate headquarters in Daytona Beach, Florida,[6] Lajba's work on each replica trophy requires six weeks of 12-hour days to create the Firebird I automobile, with all the work done by hand,[6] before it gets plated in silver by A&J Plating, also located in Omaha.[6] The first replica trophy, won in 1998 by Dale Earnhardt was originally on a marble base, but has since been switched to an acrylic stand, making it lighter.[6] For the 2008 Daytona 500, the 50th anniversary of the first race, the replica of the trophy, presented to winner Ryan Newman, was plated in gold rather than silver.[5]

The replica trophies weigh 54 pounds (24 kg), and measure 18 inches (460 mm) tall, 22 inches (560 mm) wide and 12 inches (300 mm) deep.[7]

Additional Daytona 500 trophies[edit]
The Harley J. Earl Trophy is not the only trophy awarded at the conclusion of the annual Daytona 500. The crew chief of the winning team receives the Cannonball Baker Trophy, named after the first commissioner of NASCAR; the winning team owner is awarded the Governor's Cup.[10]

Winners of the Harley J. Earl Trophy[edit]
The most Harley Earl Awards and Harley J. Earl Trophy Replicas have been won by Richard Petty, often referred to as "The King" of NASCAR.[11] Petty's seven victories lead the four Daytona 500 wins of Cale Yarborough, and three each by Bobby Allison, Dale Jarrett and Jeff Gordon. Bill Elliott, Sterling Marlin, Michael Waltrip, Matt Kenseth, Jimmie Johnson and Dale Earnhardt, Jr. have won the Daytona 500 and Harley J. Earl Trophy twice; twenty-six other drivers have been awarded the trophy once.[12] As of 2012, Trevor Bayne was the youngest winner of the trophy when he won it at age 20 years, 1 day in 2011;[13] Allison was the oldest winner (50 years, 2 months, 11 days) in 1988.[14]
In Flash Hiders there are three different play modes: a scenario mode, an "Advance mode", and a versus mode.[1] While the scenario mode limits the player to using protagonist Bang Vipot, the "Advance mode" allows the player to use his or her favorite character.[1] While the game requires the Super CD (known in North America as Turbo CD) to run, it is recommended that the "Arcade Card" is installed in the PC Engine for the game to run at its intended speed. If the game is played with a two-button controller, gently pressing the punch or kick button results in a weak attack while holding the button down executes a harder attack. If it is played with a six-button controller, four basic attacks from weak punch to hard kick are assigned to the first four buttons. Each fighter has three other gauges besides his or her health; the strength of the attacks, the speed of the player, and the toughness of the defense.

Characters[edit]
Bang Vipot: The protagonist of the game. A kickboxer from the Wallace tribe who uses the ability to turn into a tiger in one of his moves.

Tiria Rosette: A bojutsu practitioner from the Meijia tribe who uses the fire spirit, Ifreis.

Ottoh Halford: A member of the cyborg tribe, Boranzo. He also wields crowbar-tip claws on his hand.

Harman Do Elan: A member of the Wallace tribe who uses the ability to turn into a panther in one of her moves.

Rablehalt: A sword-wielding knight of the Wallace tribe who can turn into a werewolf in one of his moves.

Spenoza Thunderhead: A member of the Meijia tribe who uses the thunder spirit, Bolvick.

Calnarsa Lue Bonn: A bojutsu expert from the Boranzo tribe.

Horow: A ninja from the Boranzo tribe.

Seena Vanpied: A vampire from the Meijia tribe who uses the ice spirit, Windy.

Graneel: The game's sub-boss. He is a member of the Wallace tribe who wields a lance and can turn into a dragon.

Moonrize: The game's antagonist. A secretary of Spenoza and also a member of the Boranzo tribe.

Battle Tycoon: Flash Hiders SFX[edit]
Battle Tycoon: Flash Hiders SFX
Battle Tycoon: Flash Hiders SFX
Front cover.
Developer(s)	Right Stuff
Publisher(s)	Right Stuff
Platform(s)	Super Famicom
Release date(s)	
JP May 19, 1995
Genre(s)	Action with role-playing video game elements[2]
Mode(s)	Single-player
Multiplayer (up to 2 players)
Battle Tycoon: Flash Hiders SFX (バトルタイクーン?)[3] is a 1995 fighting video game developed and published by Right Stuff for the Super Famicom on May 19, 1995. It is an alleged sequel to the 1993 PC Engine CD-ROM ² title Flash Hiders.[4] Like its predecessor, Battle Tycoon: Flash Hiders SFX simulates the life of a fantasy martial arts prize fighter with an anime theme to it.[2]

Gameplay[edit]
With the money that the player wins per fight, he or she can go to the store from sunrise to sunset and upgrade his or her equipment. From sunset to sunrise, the player can either bet on arena fights to gain extra cash or participate in them in order to gain experience points. Also, the player has the ability to fight on the streets during any moment of the day. Computer opponents that are defeated in low levels often come back in higher level formats, although they occasionally respawn as a lower level warrior. Sometimes, a player can even fight a clone of either himself or herself. This clone will either be superior, inferior, or on equal terms to the player's character. There are six difficulty levels; Easy, Normal, Hard, Metal, Truth, and Death. The game can be played by either one or two players. There is no blood and fantasy violence (either with or without melee weapons) dominate most of the game.

By the end of most games, the player will have a wealthy, powerful fighter with the strongest gear and protection. Settings for fights can take place anywhere from military bases to arena and even the city streets. Each fighter has three other gauges besides his or her health; they determine the strength of the attacks, the speed of the player, and the toughness of the defense (guard).

Characters returned from Flash Hiders[edit]
Bang Vipot
Tiria Rosette
Ottoh Halford
Harman Do Elan
Spenoza Thunderhead
Calnarsa Lue Bonn
Seena Vanpied
Characters introduced in Battle Tycoon[edit]
Guston Slayed: A mixed martial artist of the Boranzo tribe.
Pachet Vain: A tomboyish swordswoman of the Wallace tribe who can turn into a polar bear in one of her moves.
Jail Lance: The game's antagonist. He is a sword-wielding member of the Wallace tribe who is also Bang's father. Though he has the spirit of a lion, he does not have a special move that will turn him into an animal unlike other Wallace tribe members.
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."

The Harley J. Earl Trophy is named after General Motors car designer Harley Earl. Earl, the second commissioner of NASCAR, was the designer of the Chevrolet Corvette;[1] his Firebird I concept car provides the basis of the automobile that sits atop the trophy;[2] the car is often misidentified as Sir Malcolm Campbell's "Blue Bird" land speed record car.[3] Earl was a friend of NASCAR founder Bill France, Sr., who named the trophy after him as a sign of respect.[4]

The trophy is awarded to the winner of the annual Daytona 500, known as "The Great American Race",[5] which acts as the season-opening event for the NASCAR Sprint Cup Series (formerly known as the Nextel Cup Series, Winston Cup Series, and Grand National Series), and is also considered the most prestigious and important event on the NASCAR schedule.[2] The trophy is considered to be the most coveted award a NASCAR driver can be presented with.[2][6]

The Harley J. Earl Perpetual Trophy, the "official" version of the award, is housed at Daytona 500 Experience, a museum adjacent to the Daytona International Speedway. It stands about four feet tall, and five feet wide, and is in the same triangular "tri-oval" shape of Daytona International Speedway. It is removed from its display once a year to appear in victory lane with the winner of the Daytona 500.[7] However, in 2010, the trophy was removed from the Daytona International Speedway, and transported to the Indianapolis Motor Speedway, where it was put on display alongside the Borg-Warner Trophy, awarded to the winner of the Indianapolis 500, in the Indianapolis Motor Speedway Hall of Fame Museum during the Indianapolis 500 Week.[8]

The Trophy and the Award[edit]

2008 gold-plated trophy.
Winners of the Daytona 500 through 1997 received the Harley Earl Award, a wooden trophy approximately three feet tall, adorned with silver figurines.[9] Starting in 1998, to celebrate the 40th running, individual winners of the Daytona 500 have been presented with a miniature replica of the Harley J. Earl Trophy,[9] which was recreated by John Lajba, a sculptor from Omaha, Nebraska.[6] Previously commissioned to craft a sculpture of Bill France and his wife, Ann France, for display in front of NASCAR corporate headquarters in Daytona Beach, Florida,[6] Lajba's work on each replica trophy requires six weeks of 12-hour days to create the Firebird I automobile, with all the work done by hand,[6] before it gets plated in silver by A&J Plating, also located in Omaha.[6] The first replica trophy, won in 1998 by Dale Earnhardt was originally on a marble base, but has since been switched to an acrylic stand, making it lighter.[6] For the 2008 Daytona 500, the 50th anniversary of the first race, the replica of the trophy, presented to winner Ryan Newman, was plated in gold rather than silver.[5]

The replica trophies weigh 54 pounds (24 kg), and measure 18 inches (460 mm) tall, 22 inches (560 mm) wide and 12 inches (300 mm) deep.[7]

Additional Daytona 500 trophies[edit]
The Harley J. Earl Trophy is not the only trophy awarded at the conclusion of the annual Daytona 500. The crew chief of the winning team receives the Cannonball Baker Trophy, named after the first commissioner of NASCAR; the winning team owner is awarded the Governor's Cup.[10]

Winners of the Harley J. Earl Trophy[edit]
The most Harley Earl Awards and Harley J. Earl Trophy Replicas have been won by Richard Petty, often referred to as "The King" of NASCAR.[11] Petty's seven victories lead the four Daytona 500 wins of Cale Yarborough, and three each by Bobby Allison, Dale Jarrett and Jeff Gordon. Bill Elliott, Sterling Marlin, Michael Waltrip, Matt Kenseth, Jimmie Johnson and Dale Earnhardt, Jr. have won the Daytona 500 and Harley J. Earl Trophy twice; twenty-six other drivers have been awarded the trophy once.[12] As of 2012, Trevor Bayne was the youngest winner of the trophy when he won it at age 20 years, 1 day in 2011;[13] Allison was the oldest winner (50 years, 2 months, 11 days) in 1988.[14]
The Harley J. Earl Trophy is named after General Motors car designer Harley Earl. Earl, the second commissioner of NASCAR, was the designer of the Chevrolet Corvette;[1] his Firebird I concept car provides the basis of the automobile that sits atop the trophy;[2] the car is often misidentified as Sir Malcolm Campbell's "Blue Bird" land speed record car.[3] Earl was a friend of NASCAR founder Bill France, Sr., who named the trophy after him as a sign of respect.[4]

The trophy is awarded to the winner of the annual Daytona 500, known as "The Great American Race",[5] which acts as the season-opening event for the NASCAR Sprint Cup Series (formerly known as the Nextel Cup Series, Winston Cup Series, and Grand National Series), and is also considered the most prestigious and important event on the NASCAR schedule.[2] The trophy is considered to be the most coveted award a NASCAR driver can be presented with.[2][6]

The Harley J. Earl Perpetual Trophy, the "official" version of the award, is housed at Daytona 500 Experience, a museum adjacent to the Daytona International Speedway. It stands about four feet tall, and five feet wide, and is in the same triangular "tri-oval" shape of Daytona International Speedway. It is removed from its display once a year to appear in victory lane with the winner of the Daytona 500.[7] However, in 2010, the trophy was removed from the Daytona International Speedway, and transported to the Indianapolis Motor Speedway, where it was put on display alongside the Borg-Warner Trophy, awarded to the winner of the Indianapolis 500, in the Indianapolis Motor Speedway Hall of Fame Museum during the Indianapolis 500 Week.[8]

The Trophy and the Award[edit]

2008 gold-plated trophy.
Winners of the Daytona 500 through 1997 received the Harley Earl Award, a wooden trophy approximately three feet tall, adorned with silver figurines.[9] Starting in 1998, to celebrate the 40th running, individual winners of the Daytona 500 have been presented with a miniature replica of the Harley J. Earl Trophy,[9] which was recreated by John Lajba, a sculptor from Omaha, Nebraska.[6] Previously commissioned to craft a sculpture of Bill France and his wife, Ann France, for display in front of NASCAR corporate headquarters in Daytona Beach, Florida,[6] Lajba's work on each replica trophy requires six weeks of 12-hour days to create the Firebird I automobile, with all the work done by hand,[6] before it gets plated in silver by A&J Plating, also located in Omaha.[6] The first replica trophy, won in 1998 by Dale Earnhardt was originally on a marble base, but has since been switched to an acrylic stand, making it lighter.[6] For the 2008 Daytona 500, the 50th anniversary of the first race, the replica of the trophy, presented to winner Ryan Newman, was plated in gold rather than silver.[5]

The replica trophies weigh 54 pounds (24 kg), and measure 18 inches (460 mm) tall, 22 inches (560 mm) wide and 12 inches (300 mm) deep.[7]

Additional Daytona 500 trophies[edit]
The Harley J. Earl Trophy is not the only trophy awarded at the conclusion of the annual Daytona 500. The crew chief of the winning team receives the Cannonball Baker Trophy, named after the first commissioner of NASCAR; the winning team owner is awarded the Governor's Cup.[10]

Winners of the Harley J. Earl Trophy[edit]
The most Harley Earl Awards and Harley J. Earl Trophy Replicas have been won by Richard Petty, often referred to as "The King" of NASCAR.[11] Petty's seven victories lead the four Daytona 500 wins of Cale Yarborough, and three each by Bobby Allison, Dale Jarrett and Jeff Gordon. Bill Elliott, Sterling Marlin, Michael Waltrip, Matt Kenseth, Jimmie Johnson and Dale Earnhardt, Jr. have won the Daytona 500 and Harley J. Earl Trophy twice; twenty-six other drivers have been awarded the trophy once.[12] As of 2012, Trevor Bayne was the youngest winner of the trophy when he won it at age 20 years, 1 day in 2011;[13] Allison was the oldest winner (50 years, 2 months, 11 days) in 1988.[14]
In Flash Hiders there are three different play modes: a scenario mode, an "Advance mode", and a versus mode.[1] While the scenario mode limits the player to using protagonist Bang Vipot, the "Advance mode" allows the player to use his or her favorite character.[1] While the game requires the Super CD (known in North America as Turbo CD) to run, it is recommended that the "Arcade Card" is installed in the PC Engine for the game to run at its intended speed. If the game is played with a two-button controller, gently pressing the punch or kick button results in a weak attack while holding the button down executes a harder attack. If it is played with a six-button controller, four basic attacks from weak punch to hard kick are assigned to the first four buttons. Each fighter has three other gauges besides his or her health; the strength of the attacks, the speed of the player, and the toughness of the defense.

Characters[edit]
Bang Vipot: The protagonist of the game. A kickboxer from the Wallace tribe who uses the ability to turn into a tiger in one of his moves.

Tiria Rosette: A bojutsu practitioner from the Meijia tribe who uses the fire spirit, Ifreis.

Ottoh Halford: A member of the cyborg tribe, Boranzo. He also wields crowbar-tip claws on his hand.

Harman Do Elan: A member of the Wallace tribe who uses the ability to turn into a panther in one of her moves.

Rablehalt: A sword-wielding knight of the Wallace tribe who can turn into a werewolf in one of his moves.

Spenoza Thunderhead: A member of the Meijia tribe who uses the thunder spirit, Bolvick.

Calnarsa Lue Bonn: A bojutsu expert from the Boranzo tribe.

Horow: A ninja from the Boranzo tribe.

Seena Vanpied: A vampire from the Meijia tribe who uses the ice spirit, Windy.

Graneel: The game's sub-boss. He is a member of the Wallace tribe who wields a lance and can turn into a dragon.

Moonrize: The game's antagonist. A secretary of Spenoza and also a member of the Boranzo tribe.

Battle Tycoon: Flash Hiders SFX[edit]
Battle Tycoon: Flash Hiders SFX
Battle Tycoon: Flash Hiders SFX
Front cover.
Developer(s)	Right Stuff
Publisher(s)	Right Stuff
Platform(s)	Super Famicom
Release date(s)	
JP May 19, 1995
Genre(s)	Action with role-playing video game elements[2]
Mode(s)	Single-player
Multiplayer (up to 2 players)
Battle Tycoon: Flash Hiders SFX (バトルタイクーン?)[3] is a 1995 fighting video game developed and published by Right Stuff for the Super Famicom on May 19, 1995. It is an alleged sequel to the 1993 PC Engine CD-ROM ² title Flash Hiders.[4] Like its predecessor, Battle Tycoon: Flash Hiders SFX simulates the life of a fantasy martial arts prize fighter with an anime theme to it.[2]

Gameplay[edit]
With the money that the player wins per fight, he or she can go to the store from sunrise to sunset and upgrade his or her equipment. From sunset to sunrise, the player can either bet on arena fights to gain extra cash or participate in them in order to gain experience points. Also, the player has the ability to fight on the streets during any moment of the day. Computer opponents that are defeated in low levels often come back in higher level formats, although they occasionally respawn as a lower level warrior. Sometimes, a player can even fight a clone of either himself or herself. This clone will either be superior, inferior, or on equal terms to the player's character. There are six difficulty levels; Easy, Normal, Hard, Metal, Truth, and Death. The game can be played by either one or two players. There is no blood and fantasy violence (either with or without melee weapons) dominate most of the game.

By the end of most games, the player will have a wealthy, powerful fighter with the strongest gear and protection. Settings for fights can take place anywhere from military bases to arena and even the city streets. Each fighter has three other gauges besides his or her health; they determine the strength of the attacks, the speed of the player, and the toughness of the defense (guard).

Characters returned from Flash Hiders[edit]
Bang Vipot
Tiria Rosette
Ottoh Halford
Harman Do Elan
Spenoza Thunderhead
Calnarsa Lue Bonn
Seena Vanpied
Characters introduced in Battle Tycoon[edit]
Guston Slayed: A mixed martial artist of the Boranzo tribe.
Pachet Vain: A tomboyish swordswoman of the Wallace tribe who can turn into a polar bear in one of her moves.
Jail Lance: The game's antagonist. He is a sword-wielding member of the Wallace tribe who is also Bang's father. Though he has the spirit of a lion, he does not have a special move that will turn him into an animal unlike other Wallace tribe members.
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."

The Harley J. Earl Trophy is named after General Motors car designer Harley Earl. Earl, the second commissioner of NASCAR, was the designer of the Chevrolet Corvette;[1] his Firebird I concept car provides the basis of the automobile that sits atop the trophy;[2] the car is often misidentified as Sir Malcolm Campbell's "Blue Bird" land speed record car.[3] Earl was a friend of NASCAR founder Bill France, Sr., who named the trophy after him as a sign of respect.[4]

The trophy is awarded to the winner of the annual Daytona 500, known as "The Great American Race",[5] which acts as the season-opening event for the NASCAR Sprint Cup Series (formerly known as the Nextel Cup Series, Winston Cup Series, and Grand National Series), and is also considered the most prestigious and important event on the NASCAR schedule.[2] The trophy is considered to be the most coveted award a NASCAR driver can be presented with.[2][6]

The Harley J. Earl Perpetual Trophy, the "official" version of the award, is housed at Daytona 500 Experience, a museum adjacent to the Daytona International Speedway. It stands about four feet tall, and five feet wide, and is in the same triangular "tri-oval" shape of Daytona International Speedway. It is removed from its display once a year to appear in victory lane with the winner of the Daytona 500.[7] However, in 2010, the trophy was removed from the Daytona International Speedway, and transported to the Indianapolis Motor Speedway, where it was put on display alongside the Borg-Warner Trophy, awarded to the winner of the Indianapolis 500, in the Indianapolis Motor Speedway Hall of Fame Museum during the Indianapolis 500 Week.[8]

The Trophy and the Award[edit]

2008 gold-plated trophy.
Winners of the Daytona 500 through 1997 received the Harley Earl Award, a wooden trophy approximately three feet tall, adorned with silver figurines.[9] Starting in 1998, to celebrate the 40th running, individual winners of the Daytona 500 have been presented with a miniature replica of the Harley J. Earl Trophy,[9] which was recreated by John Lajba, a sculptor from Omaha, Nebraska.[6] Previously commissioned to craft a sculpture of Bill France and his wife, Ann France, for display in front of NASCAR corporate headquarters in Daytona Beach, Florida,[6] Lajba's work on each replica trophy requires six weeks of 12-hour days to create the Firebird I automobile, with all the work done by hand,[6] before it gets plated in silver by A&J Plating, also located in Omaha.[6] The first replica trophy, won in 1998 by Dale Earnhardt was originally on a marble base, but has since been switched to an acrylic stand, making it lighter.[6] For the 2008 Daytona 500, the 50th anniversary of the first race, the replica of the trophy, presented to winner Ryan Newman, was plated in gold rather than silver.[5]

The replica trophies weigh 54 pounds (24 kg), and measure 18 inches (460 mm) tall, 22 inches (560 mm) wide and 12 inches (300 mm) deep.[7]

Additional Daytona 500 trophies[edit]
The Harley J. Earl Trophy is not the only trophy awarded at the conclusion of the annual Daytona 500. The crew chief of the winning team receives the Cannonball Baker Trophy, named after the first commissioner of NASCAR; the winning team owner is awarded the Governor's Cup.[10]

Winners of the Harley J. Earl Trophy[edit]
The most Harley Earl Awards and Harley J. Earl Trophy Replicas have been won by Richard Petty, often referred to as "The King" of NASCAR.[11] Petty's seven victories lead the four Daytona 500 wins of Cale Yarborough, and three each by Bobby Allison, Dale Jarrett and Jeff Gordon. Bill Elliott, Sterling Marlin, Michael Waltrip, Matt Kenseth, Jimmie Johnson and Dale Earnhardt, Jr. have won the Daytona 500 and Harley J. Earl Trophy twice; twenty-six other drivers have been awarded the trophy once.[12] As of 2012, Trevor Bayne was the youngest winner of the trophy when he won it at age 20 years, 1 day in 2011;[13] Allison was the oldest winner (50 years, 2 months, 11 days) in 1988.[14]
The Harley J. Earl Trophy is named after General Motors car designer Harley Earl. Earl, the second commissioner of NASCAR, was the designer of the Chevrolet Corvette;[1] his Firebird I concept car provides the basis of the automobile that sits atop the trophy;[2] the car is often misidentified as Sir Malcolm Campbell's "Blue Bird" land speed record car.[3] Earl was a friend of NASCAR founder Bill France, Sr., who named the trophy after him as a sign of respect.[4]

The trophy is awarded to the winner of the annual Daytona 500, known as "The Great American Race",[5] which acts as the season-opening event for the NASCAR Sprint Cup Series (formerly known as the Nextel Cup Series, Winston Cup Series, and Grand National Series), and is also considered the most prestigious and important event on the NASCAR schedule.[2] The trophy is considered to be the most coveted award a NASCAR driver can be presented with.[2][6]

The Harley J. Earl Perpetual Trophy, the "official" version of the award, is housed at Daytona 500 Experience, a museum adjacent to the Daytona International Speedway. It stands about four feet tall, and five feet wide, and is in the same triangular "tri-oval" shape of Daytona International Speedway. It is removed from its display once a year to appear in victory lane with the winner of the Daytona 500.[7] However, in 2010, the trophy was removed from the Daytona International Speedway, and transported to the Indianapolis Motor Speedway, where it was put on display alongside the Borg-Warner Trophy, awarded to the winner of the Indianapolis 500, in the Indianapolis Motor Speedway Hall of Fame Museum during the Indianapolis 500 Week.[8]

The Trophy and the Award[edit]

2008 gold-plated trophy.
Winners of the Daytona 500 through 1997 received the Harley Earl Award, a wooden trophy approximately three feet tall, adorned with silver figurines.[9] Starting in 1998, to celebrate the 40th running, individual winners of the Daytona 500 have been presented with a miniature replica of the Harley J. Earl Trophy,[9] which was recreated by John Lajba, a sculptor from Omaha, Nebraska.[6] Previously commissioned to craft a sculpture of Bill France and his wife, Ann France, for display in front of NASCAR corporate headquarters in Daytona Beach, Florida,[6] Lajba's work on each replica trophy requires six weeks of 12-hour days to create the Firebird I automobile, with all the work done by hand,[6] before it gets plated in silver by A&J Plating, also located in Omaha.[6] The first replica trophy, won in 1998 by Dale Earnhardt was originally on a marble base, but has since been switched to an acrylic stand, making it lighter.[6] For the 2008 Daytona 500, the 50th anniversary of the first race, the replica of the trophy, presented to winner Ryan Newman, was plated in gold rather than silver.[5]

The replica trophies weigh 54 pounds (24 kg), and measure 18 inches (460 mm) tall, 22 inches (560 mm) wide and 12 inches (300 mm) deep.[7]

Additional Daytona 500 trophies[edit]
The Harley J. Earl Trophy is not the only trophy awarded at the conclusion of the annual Daytona 500. The crew chief of the winning team receives the Cannonball Baker Trophy, named after the first commissioner of NASCAR; the winning team owner is awarded the Governor's Cup.[10]

Winners of the Harley J. Earl Trophy[edit]
The most Harley Earl Awards and Harley J. Earl Trophy Replicas have been won by Richard Petty, often referred to as "The King" of NASCAR.[11] Petty's seven victories lead the four Daytona 500 wins of Cale Yarborough, and three each by Bobby Allison, Dale Jarrett and Jeff Gordon. Bill Elliott, Sterling Marlin, Michael Waltrip, Matt Kenseth, Jimmie Johnson and Dale Earnhardt, Jr. have won the Daytona 500 and Harley J. Earl Trophy twice; twenty-six other drivers have been awarded the trophy once.[12] As of 2012, Trevor Bayne was the youngest winner of the trophy when he won it at age 20 years, 1 day in 2011;[13] Allison was the oldest winner (50 years, 2 months, 11 days) in 1988.[14]
In Flash Hiders there are three different play modes: a scenario mode, an "Advance mode", and a versus mode.[1] While the scenario mode limits the player to using protagonist Bang Vipot, the "Advance mode" allows the player to use his or her favorite character.[1] While the game requires the Super CD (known in North America as Turbo CD) to run, it is recommended that the "Arcade Card" is installed in the PC Engine for the game to run at its intended speed. If the game is played with a two-button controller, gently pressing the punch or kick button results in a weak attack while holding the button down executes a harder attack. If it is played with a six-button controller, four basic attacks from weak punch to hard kick are assigned to the first four buttons. Each fighter has three other gauges besides his or her health; the strength of the attacks, the speed of the player, and the toughness of the defense.

Characters[edit]
Bang Vipot: The protagonist of the game. A kickboxer from the Wallace tribe who uses the ability to turn into a tiger in one of his moves.

Tiria Rosette: A bojutsu practitioner from the Meijia tribe who uses the fire spirit, Ifreis.

Ottoh Halford: A member of the cyborg tribe, Boranzo. He also wields crowbar-tip claws on his hand.

Harman Do Elan: A member of the Wallace tribe who uses the ability to turn into a panther in one of her moves.

Rablehalt: A sword-wielding knight of the Wallace tribe who can turn into a werewolf in one of his moves.

Spenoza Thunderhead: A member of the Meijia tribe who uses the thunder spirit, Bolvick.

Calnarsa Lue Bonn: A bojutsu expert from the Boranzo tribe.

Horow: A ninja from the Boranzo tribe.

Seena Vanpied: A vampire from the Meijia tribe who uses the ice spirit, Windy.

Graneel: The game's sub-boss. He is a member of the Wallace tribe who wields a lance and can turn into a dragon.

Moonrize: The game's antagonist. A secretary of Spenoza and also a member of the Boranzo tribe.

Battle Tycoon: Flash Hiders SFX[edit]
Battle Tycoon: Flash Hiders SFX
Battle Tycoon: Flash Hiders SFX
Front cover.
Developer(s)	Right Stuff
Publisher(s)	Right Stuff
Platform(s)	Super Famicom
Release date(s)	
JP May 19, 1995
Genre(s)	Action with role-playing video game elements[2]
Mode(s)	Single-player
Multiplayer (up to 2 players)
Battle Tycoon: Flash Hiders SFX (バトルタイクーン?)[3] is a 1995 fighting video game developed and published by Right Stuff for the Super Famicom on May 19, 1995. It is an alleged sequel to the 1993 PC Engine CD-ROM ² title Flash Hiders.[4] Like its predecessor, Battle Tycoon: Flash Hiders SFX simulates the life of a fantasy martial arts prize fighter with an anime theme to it.[2]

Gameplay[edit]
With the money that the player wins per fight, he or she can go to the store from sunrise to sunset and upgrade his or her equipment. From sunset to sunrise, the player can either bet on arena fights to gain extra cash or participate in them in order to gain experience points. Also, the player has the ability to fight on the streets during any moment of the day. Computer opponents that are defeated in low levels often come back in higher level formats, although they occasionally respawn as a lower level warrior. Sometimes, a player can even fight a clone of either himself or herself. This clone will either be superior, inferior, or on equal terms to the player's character. There are six difficulty levels; Easy, Normal, Hard, Metal, Truth, and Death. The game can be played by either one or two players. There is no blood and fantasy violence (either with or without melee weapons) dominate most of the game.

By the end of most games, the player will have a wealthy, powerful fighter with the strongest gear and protection. Settings for fights can take place anywhere from military bases to arena and even the city streets. Each fighter has three other gauges besides his or her health; they determine the strength of the attacks, the speed of the player, and the toughness of the defense (guard).

Characters returned from Flash Hiders[edit]
Bang Vipot
Tiria Rosette
Ottoh Halford
Harman Do Elan
Spenoza Thunderhead
Calnarsa Lue Bonn
Seena Vanpied
Characters introduced in Battle Tycoon[edit]
Guston Slayed: A mixed martial artist of the Boranzo tribe.
Pachet Vain: A tomboyish swordswoman of the Wallace tribe who can turn into a polar bear in one of her moves.
Jail Lance: The game's antagonist. He is a sword-wielding member of the Wallace tribe who is also Bang's father. Though he has the spirit of a lion, he does not have a special move that will turn him into an animal unlike other Wallace tribe members.
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."
A June 1992 RFC[38] and the Internet Assigned Numbers Authority registry of character sets[12] recognize the following case-insensitive aliases for ASCII as suitable for use on the Internet:

ANSI_X3.4-1968 (canonical name)
iso-ir-6
ANSI_X3.4-1986
ISO_646.irv:1991
ASCII
ISO646-US
US-ASCII (preferred MIME name)[12]
us
IBM367
cp367
csASCII
Of these, the IANA encourages use of the name "US-ASCII" for Internet uses of ASCII (even if it is a redundant acronym, but the US is needed because of abuse of the ASCII term). One often finds this in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prologue of some XML documents.

Variants[edit]
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to represent all variants, including those that do not preserve ASCII's character-map in the 7-bit range. Furthermore the ASCII extensions have also been mislabelled as ASCII.

Many other countries developed variants of ASCII to include non-English letters (e.g. é, ñ, ß, Ł), currency symbols (e.g. £, ¥), etc.

The PETSCII code Commodore International used for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963, instead of the more common ASCII-1967, such as found on the ZX Spectrum computer. Atari 8-bit computers and Galaksija computers also used ASCII variants.

7-bit[edit]
From early in its development,[39] ASCII was intended to be just one of several national variants of an international character code standard, ultimately published as ISO/IEC 646 (1972), which would share most characters in common but assign other locally useful characters to several code points reserved for "national use." However, the four years that elapsed between the publication of ASCII-1963 and ISO's first acceptance of an international recommendation during 1967[40] caused ASCII's choices for the national use characters to seem to be de facto standards for the world, causing confusion and incompatibility once other countries did begin to make their own assignments to these code points.

ISO/IEC 646, like ASCII, was a 7-bit character set. It did not make any additional codes available, so the same code points encoded different characters in different countries. Escape codes were defined to indicate which national variant applied to a piece of text, but they were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and in general, text-processing systems could cope with only one variant anyway.

Because the bracket and brace characters of ASCII were assigned to "national use" code points that were used for accented letters in other national variants of ISO/IEC 646, a German, French, or Swedish, etc. programmer using their national variant of ISO/IEC 646, rather than ASCII, had to write, and thus read, something such as

ä aÄiÜ='Ön'; ü
instead of

{ a[i]='\n'; }
C trigraphs were created to solve this problem for ANSI C, although their late introduction and inconsistent implementation in compilers limited their use. Many programmers kept their computers on US-ASCII, so plain-text in Swedish, German etc. (for example, in e-mail or Usenet) contained "{, }" and similar variants in the middle of words, something those programmers got used to.

8-bit[edit]
Eventually, as 8-, 16- and 32-bit (and later 64-bit) computers began to replace 18- and 36-bit computers as the norm, it became common to use an 8-bit byte to store each character in memory, providing an opportunity for extended, 8-bit, relatives of ASCII. In most cases these developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e., 7-bit) characters.

Most early home computer systems developed their own 8-bit character sets containing line-drawing and game glyphs, and often filled in some or all of the control characters from 0-31 with more graphics. Kaypro CP/M computers used the "upper" 128 characters for the Greek alphabet. The IBM PC defined code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal; this was one of the first extensions designed more for international languages than for block graphics. The Macintosh defined Mac OS Roman and Postscript also defined a set, both of these contained both international letters and typographic punctuation marks instead of graphics, more like modern character sets. The ISO/IEC 8859 standard (derived from the DEC-MCS) finally provided a standard that most systems copied (at least as accurately as they copied ASCII, but with many substitutions). A popular further extension designed by Microsoft, Windows-1252 (often mislabeled as ISO-8859-1), added the typographic punctuation marks needed for traditional text printing.

ISO-8859-1, Windows-1252, and the original 7-bit ASCII were the most common character encodings until 2008 when UTF-8 became more common.[14]

Unicode[edit]
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).

To allow backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and ASCII (when prefixed with 0 as the eighth bit) is valid UTF-8.

Order[edit]
ASCII-code order is also called ASCIIbetical order.[41] Collation of data is sometimes done in this order rather than "standard" alphabetical order (collating sequence). The main deviations in ASCII order are:

All uppercase come before lowercase letters, for example, "Z" before "a"
Digits and many punctuation marks come before letters; for example, "4" precedes "one"
Numbers are sorted naïvely as strings; for example, "10" precedes "2"
An intermediate order—readily implemented—converts uppercase letters to lowercase before comparing ASCII values. Naïve number sorting can be averted by zero-filling all numbers (e.g. "02" will sort before "10" as expected), although this is an external fix and has nothing to do with the ordering itself.

LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two algorithms form the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed the basis of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available,[dubious – discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004.[4]

Contents  [hide] 
1 Theoretical efficiency
2 LZ77
2.1 Implementations
3 LZ78
4 References
5 External links
Theoretical efficiency[edit]
In the second of the two papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This measure gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the sequence grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77 algorithms achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distance characters behind it in the uncompressed stream". (The "distance" is sometimes called the "offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometimes called sliding window compression. The encoder needs to keep this data to look for matches, and the decoder needs to keep this data to interpret the matches the encoder refers to. The larger the sliding window is, the longer back the encoder may search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten characters from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is copied over, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of the copy-from position. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of data multiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of the search window, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen) characters that comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past the search window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until the run pattern is interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appended to the output buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single buffered run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L characters are read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write pointer by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of the window and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient length is met, and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their compressed data to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part of a length-distance pair). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed that match. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a length-distance pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format, a length-distance pair is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3 go to encoding the length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a length-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entire length-distance pair can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines LZ77 with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separate alphabet; since a distance only occurs just after a length, it cannot be mistaken for another kind of symbol or vice-versa.
LZ78[edit]
LZ78 algorithms achieve compression by replacing repeated occurrences of data with references to a dictionary that is built based on the input data stream. Each dictionary entry is of the form dictionary[...] = {index, character}, where index is the index to a previous dictionary entry, and character is appended to the string represented by dictionary[index]. For example, "abc" would be stored (in reverse order) as follows: dictionary[k] = {j, 'c'}, dictionary[j] = {i, 'b'}, dictionary[i] = {0, 'a'}, where an index of 0 specifies the first character of a string. The algorithm initializes last matching index = 0 and next available index = 1. For each character of the input stream, the dictionary is searched for a match: {last matching index, character}. If a match is found, then last matching index is set to the index of the matching entry, and nothing is output. If a match is not found, then a new dictionary entry is created: dictionary[next available index] = {last matching index, character}, and the algorithm outputs last matching index, followed by character, then resets last matching index = 0 and increments next available index. Once the dictionary is full, no more entries are added. When the end of the input stream is reached, the algorithm outputs last matching index. Note that strings are stored in the dictionary in reverse order, which an LZ78 decoder will have to deal with.

LZW is an LZ78-based algorithm that uses a dictionary pre-initialized with all possible characters (symbols), (or emulation of a pre-initialized dictionary). The main improvement of LZW is that when a match is not found, the current input stream character is assumed to be the first character of an existing string in the dictionary (since the dictionary is initialized with all possible characters), so only the last matching index is output (which may be the pre-initialized dictionary index corresponding to the previous (or the initial) input character). Refer to the LZW article for implementation details.

LZ77 foi um dos algoritmos de compressão de dados desenvolvidos por Abraham Lempel e Jacob Ziv em 1977, juntamente com o outro algoritmo de compressão LZ78 publicado em 1978. Nos primeiros artigos publicados eles eram conhecidos por LZ1 e LZ2, respectivamente, e só depois ganharam o ano de sua publicação em suas siglas.1

O algoritmo LZ77 se baseia na utilização das partes que já foram lidas de um arquivo como um dicionário, substituindo as próximas ocorrências das mesmas seqüências de caracteres pela posição (absoluta ou relativa) da sua última ocorrência. Para limitar o espaço de busca e de endereçamento necessário, as ocorrências anteriores são limitadas por uma "janela deslizante" (do inglês sliding window) que tem tamanho fixo e "desliza" sobre o arquivo, delimitando o início e fim da área onde serão buscadas as ocorrências anteriores. O tamanho desta janela é um dos fatores primordiais para se ajustar a performance desse algoritmo.

Índice  [esconder] 
1 Algoritmo
2 Exemplo
3 Aplicações
4 Exemplo de implementação
5 Referências
6 Bibliografia
7 Ver também
Algoritmo[editar | editar código-fonte]
O algoritmo LZ77 é relativamente simples. Define-se inicialmente duas estruturas que serão usadas: A janela de procura, e o buffer de look-ahead (num tradução livre poderia ser chamado de buffer de pré-visualização). A janela representa as partes do arquivo que já foram lidos, enquanto o look-ahead representa o que ainda será lido e processado pelo algoritmo. Na prática, o look-ahead é preenchido de antemão com os próximos bytes a serem processados pelo compressor. A janela tem tamanho definido, e deve permitir que os dados sejam enfileirados dentro dela, eliminando os bytes mais antigos quando seu limite de tamanho é atingido. O buffer de look-ahead também tem tamanho definido, em geral dezenas de vezes menor que a janela.

De posse dessas estruturas verificamos a sequência de caracteres atualmente presente no buffer, e qual o maior casamento de prefixo dessa seqüência dentro da janela (qual a maior sequência da janela casa exatamente com o início da seqüência do buffer). Ao encontrar tal sequência emitimos na saída a tupla (S_{pos}, S_{tam}, c) onde S_{pos} é a posição da seqüência casada dentro da janela (contada em geral de traz para diante), S_{tam} é o tamanho dessa seqüência, e c é o próximo caractere presente no buffer depois dessa seqüência. Este caractere c é comumente chamado de literal, ou caractere literal (do inglês literal character).

Transferimos então toda a sequência casada e mais o caractere extra para a janela (chama-se esse processo de deslizamento a janela ou window slide em inglês), que tem seus elementos mais antigos removidos (caso esteja cheia). O buffer é preenchido com novos dados lidos do arquivo, e continuamos o processo até o final do arquivo.

No caso de não ser encontrado nenhum casamento dentro da janela, emite-se a tupla (0, 0, c), indicando que houve um "casamento" de tamanho 0, e apenas o caractere c é transferido para o buffer.

O processo de descompressão é bem mais simples pois não precisa fazer nenhum tipo de casamento de padrão, basta copiar os caracteres indicados pela tupla, na quantidade indicada, para a saída e acrescentar o caractere c, repetindo o processo até o fim das tuplas. Por essa diferença grande entre complexidade de compressão e descompressão diz-se que o algoritmo LZ77 é um algoritmo de compressão assimétrico.

Note que o tamanho da janela e do buffer impactam diretamente na performance do compressor: quanto maior eles forem, melhor a compressão, mas também mais lenta ela fica. O tamanho dessas estruturas deve ser bem estudado quando da implementação desse algoritmo.

# !/usr/bin/python
# coding: utf-8
 
import sys
 
class lz77:
    """
       Esta classe comprime uma seqüencia de caracteres usando
       o algoritmo LZ77 como descrito em
       http://pt.wikipedia.org/wiki/LZ77
 
       Esta é uma implementação didática, para exemplificar
       o funcionamento do algoritmo, e não possui nenhum tipo de
       otimização, por isso seu desempenho em situações reais 
       deve ser muito abaixo do esperado.
    """
    def __init__(self, window_size = 65535, buffer_size=255):
        """
           Carrega os parâmetros de tamanho de janela e buffer 
           de look-ahead
        """
        self.window_size = window_size
        self.buffer_size = buffer_size
    def encode(self, str):
        """
            Aplica o algoritmo LZ77 na cadeia de entrada, gerando
            uma lista de "tuplas" na saída. Cada tupla corresponde
            a (posição, tamanho, literal) onde posição é a posição
            relativa da cadeia encontrada na janela, tamanho é o 
            tamanho dessa cadeia e literal é o símbolo que segue
            a cadeia nessa seqüência.
        """
        ret = []
        i = 0
        while i < len(str):
            begin_window = i-self.window_size
            if begin_window < 0:
                begin_window = 0
            window = str[begin_window:i]
            buffer = str[i:i+self.buffer_size]
            tuple = (0, 0, str[i])
# Este "loop" é o "coração" do algoritmo. Aqui procuramos
# a maior seqüência dentro da janela (window) que case
# com o início do buffer. A implementação atual simplesmente
# procura por ocorrências de substrings cada vez menores
# do buffer até encontrar alguma. Implementações mais
# eficientes usariam um dicionário de prefixos, uma trie
# ou uma tabela de espalhamento.
            for size in range(len(buffer), 0, -1):
                index = window.rfind(buffer[0:size])
                if index >= 0:
                    literal = '' # a string vazia representa 
# o final do arquivo.
                    if i + size < len(str):
                        literal = str[i+size]
                    tuple = (len(window)-index-1, size, literal)
                    break
            i = i + tuple[1] + 1
            ret = ret + [tuple]
        return ret
    def decode(self, list):
        """
            A decodificação é extremamente simples: basta copiar a
            subseqüência indicada pela tupla para o final da seqüência
            de saída e acrescentar o novo caractere literal.
        """
        ret = ''
        for tuple in list:
            pos = len(ret) - tuple[0] - 1
            ret = ret + ret[pos:pos+tuple[1]] + tuple[2]
        return ret
 
if __name__ == "__main__":
    str = 'A_ASA_DA_CASA'
    encoder = lz77(8,4)
    encoded = encoder.encode(str)
    print encoded
 
    decoder = lz77(8,4)
    decoded = decoder
	
	
A Fortaleza Romana de Castleshaw foi um castro (acampamento) na província romana da Britânia. Acredita-se que o forte localiza-se sobre o assentamento Brigante de Rigoduno, embora não haja evidências para comprovar tal fato. As ruínas da fortaleza estão localizadas em Castle Hill, ao leste do Vale de Castleshaw, ao sopé de Standedge, porém ainda sobre o vale. 1 A colina fica à beira de Castleshaw em Grande Manchester. A fortaleza foi construída em 79 d.C. mas foi abandonada próximo ao ano 90 d.C. Foi, então, substituída por um forte menor, construído no ano 105, civis passaram a ocupar os arredores desse. Ele pode ter servido como centro logístico e administrativo, mas foi abandonado durante os anos 120. O local foi sujeito a investigações antiquárias e arqueologia desde o século XVIII, o assentamento civil, por sua vez não foi descoberto até os anos 1990. A fortaleza, o forte e o assentamento civil são todos protegidos como Scheduled Ancient Monument2 , sendo assim reconhecida como um sítio arqueológico ou edificação nacionalmente importante e protegendo-a, assim, contra reformas não autorizadas. 3

Roman[edit]
The fort at Castleshaw, constructed from turf and timber, was built around 79 and guarded the York to Chester Roman road.[1] Due to the site's protected status as a Scheduled Ancient Monument it has not been possible to excavate the fort, however previous trenches have demonstrated that the fort had two phases to its construction.[6] The location of the fort's granary, stables, the principia (headquarters), the praetorium (commander's tent), and six long narrow buildings which are possibly workshops or storerooms are all known.[6] The fort was small, would probably have been home to around 500 soldiers of an auxiliary cohort,[6] and fell out of use during the mid AD 90s.[1] Rather than allow the defences to fall into potentially hostile hands or be used against Rome, the fort was slighted.

The fort was replaced by a fortlet, also built using turf and timber, in AD 105. Although the fortlet was built on the same site as the fort, it did not use the same foundation trenches.[6] There were two construction phases of the fortlet, the second – dating to c. 120 – featured gates, an oven, a well, a granary, a hypocaust a workshop, barracks, a commanders house, a courtyard building, and possibly a latrine.[7] The barracks were built to accommodate 48 soldiers and even with administrative staff and officers, the garrison of the fortlet would have numbered less than 100.[8] The first phase was laid out along the same lines as the second phase.[7] The fortlet defences – as with most other fortlets – were designed to withstand attacks from brigands or hold off an enemy until reinforcements from the main army could arrive rather than withstand a determined attack.[9] A civilian settlement or vicus grew around the fortlet in the early 2nd century.[8] It probably would have been home to those who benefited from trade with the garrison or hangers on of the soldiers. Since it is unlikely that a garrison of under 100 could have supported a vicus, it has been suggested that the fortlet was a commissary fortlet, one which was the administrative and logistical centre of part of the Roman army.[8][10] With soldiers regularly arriving to collect pay and orders, a vicus could have been supported.[8] The fortlet fell out of use in the mid 120s. The fort and fortlet of Castleshaw were superseded by the neighbouring forts at Manchester and Slack.[11] The vicus was abandoned around the same time as the fortlet fell out of use.[12]

According to Ptolemy, there was a polis called Rigodunum belonging to the Brigantes near the position of Castleshaw.[13] Rigodunum means "royal fort".[14] Although it has been suggested that Castleshaw is the location of the Brigantine settlement, there is no evidence to support this.[13] Stamps on two tegulae, produced at the Roman tilery at Grimescar Wood near Huddersfield, suggest the fortlet was supplied by the Cohors III Bracaraugustanorum from Pannonia, maybe even garrisoned by them at one stage.[15] Similar stamps have been found in the forts at Manchester, Slack, and Ebchester, indicating these forts were linked.[15]

Post-Roman[edit]

A plan of Castleshaw drawn by Thomas Percival in 1752 showing the fort and the later fortlet
After being abandoned by the Romans, Castleshaw was rediscovered by antiquarian Thomas Percival in 1752. The remains were in good enough condition for him to draw a plan and he commented that he was "pleased to find a double Roman camp". He also remarked that the Roman road from Manchester running east to the Pennines was "the finest remain of a Roman road in England that I ever saw".[4] The site has suffered damage from ploughing in the 18th and 19th centuries as it is situated in one of the best draining areas of the valley.[4] In 1897, a local antiquarian and poet, Ammon Wrigley, dug several trenches on the site. He did not record the results of his digging and unrecorded digs continued on and off until 1907.[16] In 1907, the site was bought for the purpose of organised excavation and survey which continued from 1907 to 1908 under the supervision of Francis Bruton who had recently been involved with the excavation of Mamucium.[17] The spoil heaps from the 1907–08 dig were never levelled, leaving a series of misleading modern earthworks on the interior of the site.[18]

Under the supervision of the University of Manchester, further excavation was undertaken on the site in 1957–61 and 1963–64.[18] Between 1984 and 1988, Greater Manchester Archaeological Unit undertook excavations and restoration of the site. A group led by Professor Barri Jones – an expert on Roman Britain – was set up to co-ordinate the work.[19] North West Water, then the owners of the site, ensured the area would not be used for agriculture. In an attempt to make the site accessible to the public, the outline of the fort and fortlet was marked out in low mounds and an education centre was set up nearby.[19] The area beyond the fort was investigated for the first time in 1995–96; archaeologists were searching for a civilian settlement or vicus associated with the fort.[20] Surveys revealed a settlement triangular in shape and to the south of the fort.[20] The vicus is listed as a Scheduled Ancient Monument with the fort and fortlet.[21]

Layout[edit]

A plan of Castleshaw drawn by Francis Bruton in 1908 showing the fort and the later fortlet in detail
The fort was rectangular in shape and had sides of 115 metres (377 ft) and 100 metres (330 ft), covering an area of approximately 1.2 hectares (3.0 acres).[1][2] The fortlet was built over the south of the fort, making it difficult to discover what lay beneath.[18] It has been possible to however to ascertain that barrack buildings lay on the east side of the fort, a granary on the north, and the principia and praetorium to the south west.[6][22]

The fortlet was rectangular, with sides of 50 metres (160 ft) by 40 metres (130 ft), and covered 1,950 square metres (0.48 acres).[1][2] It was originally thought to be surrounded by a single Punic ditch but investigation revealed there to be two Punic ditches separated by a 2 metres (6.6 ft) wide berm.[23] The inner ditch was 3.9 metres (13 ft) wide and 1.3 metres (4.3 ft) deep while the outer ditch was 2.5 metres (8.2 ft) wide and 0.9 metres (3.0 ft) deep.[24] A Punic ditch is a defensive v-shaped ditch with one side much steeper than the other; the ditches surrounding the fortlet had an outer face at 27 degrees and the inner face at 69 degrees.[24] The rampart behind the ditches only survives to 0.5 metres (1.6 ft) at its highest point.[9] It was built from turf on top of sandy clay with a rubble foundation.[9] The fortlet ramparts to the south lay on top of the slighted fort ramparts.[25] Whether corner towers were a feature of the fortlet is unknown, no evidence remains aside from a single posthole, although only the north and east corners survive in good condition.[26] There were two gateways, one to the north and one to the south.[27]

A civilian settlement is located to the south of the fortlet's defences.[28] The extent of the vicus is uncertain,[29] however, test pits have indicated that it probably extends 12 metres (39 ft) west to east and between 25 metres (82 ft) and 35 metres (115 ft) to south.[28]

In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

Charlotte grew up in the town of Hoddesdon, Hertfordshire and attended Sheredes, the local comprehensive school. Her father died of leukaemia when she was six years old, leaving her alone with her mother Margot, brother Richard and sister Catherine and in a position of some responsibility, being the eldest. She went on to Imperial College, London where she studied biochemistry and later gained a PhD in molecular biology. Charlotte lived in Paris for a time, and also made several visits to Africa during her time at university.[1]

In 1999, having recently finished her PhD, during which time she had been a volunteer with St. John Ambulance in Hammersmith, Charlotte made the decision to become a volunteer science teacher with VSO. She was posted to the village of Shyogwe, near Gitarama in southern Rwanda, one of 23 in the second wave of volunteers sent by VSO, who had recently opened a programme to help rebuild the country shattered by the 1994 genocide. Charlotte enjoyed her time in Rwanda and integrated well into the local community, despite having to teach in French and being one of only a handful of white people in the area.[1]

In late 2000, Charlotte met and fell in love with Richard Ndereyimana, a Burundian who had been in Rwanda since 1997, first as a Dominican monk and later as a teacher. A few weeks later the couple decided to get engaged. They spent Christmas together with other volunteers by Lake Kivu, then decided to travel to Bujumubura, the Burundian capital to meet with Richard's family, despite the fact that the whole of Burundi, and particularly rural areas, was in a state of civil war and out of bounds to VSO volunteers.[2]

Death[edit]
Main article: Titanic Express massacre
The couple decided to travel with the now defunct Titanic Express bus service from Kigali to Bujumbura, a journey usually taking around seven hours, to introduce Charlotte to Richard's family.[3] They crossed the border and reached the village of Kilima, only 18 miles from their destination,[4] when the bus was ambushed from all sides by armed members of the FNL Hutu extremist group. They demanded money first, and then divided the passengers by ethnicity. The Hutus and most Congolese on the bus were spared but the Tutsis and Charlotte, 21 people in all, were forced to lie face down on the ground and shot one-by-one. Charlotte and Richard were the first to be killed, with the attackers accusing Charlotte of being from the group which supplied the weapons for the Burundi Civil War, a reference to the fact that white people (from Eastern Europe) had supplied the weaponry possessed by most of the combatants, including the guns which were actually used in the killings.[2] Charlotte's body was retrieved from the scene by VSO Rwanda officials and flown back to the UK.

Aftermath[edit]
In the weeks following the killings, Charlotte's mother and her younger brother, Richard, made public appeals to the British government to investigate the incident and to treat it as a War Crime,[5] a move which met with limited success, Richard claiming he was "fobbed off" by the Foreign Office.[2] Richard continued his enquiries personally, however, and via the Human Rights Watch organisation and various contacts he had made in Rwanda and Burundi, he established that the FNL, under the leadership of Albert Sibomana, were responsible for the killing. Richard managed to get hold of a copy of an internal FNL memo detailing the number of victims and bullets used, plus the items stolen. He also found Pierre Nzeyimana, one of the very few survivors of the massacre, who described to him exactly what had happened.[2]

The FNL finally admitted responsibility for the massacre in 2005, but by then they, and indeed Sibomana himself, were being given "provisional immunity" by the Burundi government and the international community as part of a tentative peace process being negotiated in the country.[2]

In 2006, Richard wrote a book entitled Titanic Express: Finding Answers in the Aftermath of Terror, describing the events leading up to his sister's death and his own efforts in tracking down and attempting to bring her killers to justice.

The Charlotte Wilson Memorial Fund[edit]
Charlotte's family established the Charlotte Wilson Memorial Fund [1] a few weeks after her death to support students in financial difficulty at Shyogwe school, where Charlotte had been teaching. By 4 June 2001, (the day that would have been Charlotte's 28th birthday) the fund had raised more than £10,000 [2], and has since widened its activities to support HIV awareness campaigns in Rwanda and peacebuilding work in Burundi. In Titanic Express, Richard Wilson writes of his pride in the fund's success:

"We believe, as Charlotte did, that Africa's problems can only be solved by Africans themselves, but that our solidarity can help. A week after the August 2004 Gatumba massacre, a multi-ethnic group of Burundian volunteers from 'Youth Intervention for Peace' took food and clothes to the survivors, paid for in part by the Charlotte Wilson Memorial Fund. It was only a small gesture, but it was something they could do."

The Harley J. Earl Trophy is named after General Motors car designer Harley Earl. Earl, the second commissioner of NASCAR, was the designer of the Chevrolet Corvette;[1] his Firebird I concept car provides the basis of the automobile that sits atop the trophy;[2] the car is often misidentified as Sir Malcolm Campbell's "Blue Bird" land speed record car.[3] Earl was a friend of NASCAR founder Bill France, Sr., who named the trophy after him as a sign of respect.[4]

The trophy is awarded to the winner of the annual Daytona 500, known as "The Great American Race",[5] which acts as the season-opening event for the NASCAR Sprint Cup Series (formerly known as the Nextel Cup Series, Winston Cup Series, and Grand National Series), and is also considered the most prestigious and important event on the NASCAR schedule.[2] The trophy is considered to be the most coveted award a NASCAR driver can be presented with.[2][6]

The Harley J. Earl Perpetual Trophy, the "official" version of the award, is housed at Daytona 500 Experience, a museum adjacent to the Daytona International Speedway. It stands about four feet tall, and five feet wide, and is in the same triangular "tri-oval" shape of Daytona International Speedway. It is removed from its display once a year to appear in victory lane with the winner of the Daytona 500.[7] However, in 2010, the trophy was removed from the Daytona International Speedway, and transported to the Indianapolis Motor Speedway, where it was put on display alongside the Borg-Warner Trophy, awarded to the winner of the Indianapolis 500, in the Indianapolis Motor Speedway Hall of Fame Museum during the Indianapolis 500 Week.[8]

The Trophy and the Award[edit]

2008 gold-plated trophy.
Winners of the Daytona 500 through 1997 received the Harley Earl Award, a wooden trophy approximately three feet tall, adorned with silver figurines.[9] Starting in 1998, to celebrate the 40th running, individual winners of the Daytona 500 have been presented with a miniature replica of the Harley J. Earl Trophy,[9] which was recreated by John Lajba, a sculptor from Omaha, Nebraska.[6] Previously commissioned to craft a sculpture of Bill France and his wife, Ann France, for display in front of NASCAR corporate headquarters in Daytona Beach, Florida,[6] Lajba's work on each replica trophy requires six weeks of 12-hour days to create the Firebird I automobile, with all the work done by hand,[6] before it gets plated in silver by A&J Plating, also located in Omaha.[6] The first replica trophy, won in 1998 by Dale Earnhardt was originally on a marble base, but has since been switched to an acrylic stand, making it lighter.[6] For the 2008 Daytona 500, the 50th anniversary of the first race, the replica of the trophy, presented to winner Ryan Newman, was plated in gold rather than silver.[5]

The replica trophies weigh 54 pounds (24 kg), and measure 18 inches (460 mm) tall, 22 inches (560 mm) wide and 12 inches (300 mm) deep.[7]

Additional Daytona 500 trophies[edit]
The Harley J. Earl Trophy is not the only trophy awarded at the conclusion of the annual Daytona 500. The crew chief of the winning team receives the Cannonball Baker Trophy, named after the first commissioner of NASCAR; the winning team owner is awarded the Governor's Cup.[10]

Winners of the Harley J. Earl Trophy[edit]
The most Harley Earl Awards and Harley J. Earl Trophy Replicas have been won by Richard Petty, often referred to as "The King" of NASCAR.[11] Petty's seven victories lead the four Daytona 500 wins of Cale Yarborough, and three each by Bobby Allison, Dale Jarrett and Jeff Gordon. Bill Elliott, Sterling Marlin, Michael Waltrip, Matt Kenseth, Jimmie Johnson and Dale Earnhardt, Jr. have won the Daytona 500 and Harley J. Earl Trophy twice; twenty-six other drivers have been awarded the trophy once.[12] As of 2012, Trevor Bayne was the youngest winner of the trophy when he won it at age 20 years, 1 day in 2011;[13] Allison was the oldest winner (50 years, 2 months, 11 days) in 1988.[14]
The Harley J. Earl Trophy is named after General Motors car designer Harley Earl. Earl, the second commissioner of NASCAR, was the designer of the Chevrolet Corvette;[1] his Firebird I concept car provides the basis of the automobile that sits atop the trophy;[2] the car is often misidentified as Sir Malcolm Campbell's "Blue Bird" land speed record car.[3] Earl was a friend of NASCAR founder Bill France, Sr., who named the trophy after him as a sign of respect.[4]

The trophy is awarded to the winner of the annual Daytona 500, known as "The Great American Race",[5] which acts as the season-opening event for the NASCAR Sprint Cup Series (formerly known as the Nextel Cup Series, Winston Cup Series, and Grand National Series), and is also considered the most prestigious and important event on the NASCAR schedule.[2] The trophy is considered to be the most coveted award a NASCAR driver can be presented with.[2][6]

The Harley J. Earl Perpetual Trophy, the "official" version of the award, is housed at Daytona 500 Experience, a museum adjacent to the Daytona International Speedway. It stands about four feet tall, and five feet wide, and is in the same triangular "tri-oval" shape of Daytona International Speedway. It is removed from its display once a year to appear in victory lane with the winner of the Daytona 500.[7] However, in 2010, the trophy was removed from the Daytona International Speedway, and transported to the Indianapolis Motor Speedway, where it was put on display alongside the Borg-Warner Trophy, awarded to the winner of the Indianapolis 500, in the Indianapolis Motor Speedway Hall of Fame Museum during the Indianapolis 500 Week.[8]

The Trophy and the Award[edit]

2008 gold-plated trophy.
Winners of the Daytona 500 through 1997 received the Harley Earl Award, a wooden trophy approximately three feet tall, adorned with silver figurines.[9] Starting in 1998, to celebrate the 40th running, individual winners of the Daytona 500 have been presented with a miniature replica of the Harley J. Earl Trophy,[9] which was recreated by John Lajba, a sculptor from Omaha, Nebraska.[6] Previously commissioned to craft a sculpture of Bill France and his wife, Ann France, for display in front of NASCAR corporate headquarters in Daytona Beach, Florida,[6] Lajba's work on each replica trophy requires six weeks of 12-hour days to create the Firebird I automobile, with all the work done by hand,[6] before it gets plated in silver by A&J Plating, also located in Omaha.[6] The first replica trophy, won in 1998 by Dale Earnhardt was originally on a marble base, but has since been switched to an acrylic stand, making it lighter.[6] For the 2008 Daytona 500, the 50th anniversary of the first race, the replica of the trophy, presented to winner Ryan Newman, was plated in gold rather than silver.[5]

The replica trophies weigh 54 pounds (24 kg), and measure 18 inches (460 mm) tall, 22 inches (560 mm) wide and 12 inches (300 mm) deep.[7]

Additional Daytona 500 trophies[edit]
The Harley J. Earl Trophy is not the only trophy awarded at the conclusion of the annual Daytona 500. The crew chief of the winning team receives the Cannonball Baker Trophy, named after the first commissioner of NASCAR; the winning team owner is awarded the Governor's Cup.[10]

Winners of the Harley J. Earl Trophy[edit]
The most Harley Earl Awards and Harley J. Earl Trophy Replicas have been won by Richard Petty, often referred to as "The King" of NASCAR.[11] Petty's seven victories lead the four Daytona 500 wins of Cale Yarborough, and three each by Bobby Allison, Dale Jarrett and Jeff Gordon. Bill Elliott, Sterling Marlin, Michael Waltrip, Matt Kenseth, Jimmie Johnson and Dale Earnhardt, Jr. have won the Daytona 500 and Harley J. Earl Trophy twice; twenty-six other drivers have been awarded the trophy once.[12] As of 2012, Trevor Bayne was the youngest winner of the trophy when he won it at age 20 years, 1 day in 2011;[13] Allison was the oldest winner (50 years, 2 months, 11 days) in 1988.[14]
In Flash Hiders there are three different play modes: a scenario mode, an "Advance mode", and a versus mode.[1] While the scenario mode limits the player to using protagonist Bang Vipot, the "Advance mode" allows the player to use his or her favorite character.[1] While the game requires the Super CD (known in North America as Turbo CD) to run, it is recommended that the "Arcade Card" is installed in the PC Engine for the game to run at its intended speed. If the game is played with a two-button controller, gently pressing the punch or kick button results in a weak attack while holding the button down executes a harder attack. If it is played with a six-button controller, four basic attacks from weak punch to hard kick are assigned to the first four buttons. Each fighter has three other gauges besides his or her health; the strength of the attacks, the speed of the player, and the toughness of the defense.

Characters[edit]
Bang Vipot: The protagonist of the game. A kickboxer from the Wallace tribe who uses the ability to turn into a tiger in one of his moves.

Tiria Rosette: A bojutsu practitioner from the Meijia tribe who uses the fire spirit, Ifreis.

Ottoh Halford: A member of the cyborg tribe, Boranzo. He also wields crowbar-tip claws on his hand.

Harman Do Elan: A member of the Wallace tribe who uses the ability to turn into a panther in one of her moves.

Rablehalt: A sword-wielding knight of the Wallace tribe who can turn into a werewolf in one of his moves.

Spenoza Thunderhead: A member of the Meijia tribe who uses the thunder spirit, Bolvick.

Calnarsa Lue Bonn: A bojutsu expert from the Boranzo tribe.

Horow: A ninja from the Boranzo tribe.

Seena Vanpied: A vampire from the Meijia tribe who uses the ice spirit, Windy.

Graneel: The game's sub-boss. He is a member of the Wallace tribe who wields a lance and can turn into a dragon.

Moonrize: The game's antagonist. A secretary of Spenoza and also a member of the Boranzo tribe.

Battle Tycoon: Flash Hiders SFX[edit]
Battle Tycoon: Flash Hiders SFX
Battle Tycoon: Flash Hiders SFX
Front cover.
Developer(s)	Right Stuff
Publisher(s)	Right Stuff
Platform(s)	Super Famicom
Release date(s)	
JP May 19, 1995
Genre(s)	Action with role-playing video game elements[2]
Mode(s)	Single-player
Multiplayer (up to 2 players)
Battle Tycoon: Flash Hiders SFX (バトルタイクーン?)[3] is a 1995 fighting video game developed and published by Right Stuff for the Super Famicom on May 19, 1995. It is an alleged sequel to the 1993 PC Engine CD-ROM ² title Flash Hiders.[4] Like its predecessor, Battle Tycoon: Flash Hiders SFX simulates the life of a fantasy martial arts prize fighter with an anime theme to it.[2]

Gameplay[edit]
With the money that the player wins per fight, he or she can go to the store from sunrise to sunset and upgrade his or her equipment. From sunset to sunrise, the player can either bet on arena fights to gain extra cash or participate in them in order to gain experience points. Also, the player has the ability to fight on the streets during any moment of the day. Computer opponents that are defeated in low levels often come back in higher level formats, although they occasionally respawn as a lower level warrior. Sometimes, a player can even fight a clone of either himself or herself. This clone will either be superior, inferior, or on equal terms to the player's character. There are six difficulty levels; Easy, Normal, Hard, Metal, Truth, and Death. The game can be played by either one or two players. There is no blood and fantasy violence (either with or without melee weapons) dominate most of the game.

By the end of most games, the player will have a wealthy, powerful fighter with the strongest gear and protection. Settings for fights can take place anywhere from military bases to arena and even the city streets. Each fighter has three other gauges besides his or her health; they determine the strength of the attacks, the speed of the player, and the toughness of the defense (guard).

Characters returned from Flash Hiders[edit]
Bang Vipot
Tiria Rosette
Ottoh Halford
Harman Do Elan
Spenoza Thunderhead
Calnarsa Lue Bonn
Seena Vanpied
Characters introduced in Battle Tycoon[edit]
Guston Slayed: A mixed martial artist of the Boranzo tribe.
Pachet Vain: A tomboyish swordswoman of the Wallace tribe who can turn into a polar bear in one of her moves.
Jail Lance: The game's antagonist. He is a sword-wielding member of the Wallace tribe who is also Bang's father. Though he has the spirit of a lion, he does not have a special move that will turn him into an animal unlike other Wallace tribe members.
